{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-11T15:25:28.645812Z","iopub.status.busy":"2023-10-11T15:25:28.645383Z","iopub.status.idle":"2023-10-11T15:25:29.102226Z","shell.execute_reply":"2023-10-11T15:25:29.100980Z","shell.execute_reply.started":"2023-10-11T15:25:28.645762Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/house-prices-advanced-regression-techniques/sample_submission.csv\n","/kaggle/input/house-prices-advanced-regression-techniques/data_description.txt\n","/kaggle/input/house-prices-advanced-regression-techniques/train.csv\n","/kaggle/input/house-prices-advanced-regression-techniques/test.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["# 1.Plotly中的graph_objects和express\n","Plotly是一个用于制作可视化图表的Python库。它提供了两个主要的子库：graph_objects和express。\n","\n","graph_objects提供了更灵活的图表制作方式，这意味着你可以更好地控制每个元素的外观和样式。它支持多种类型的图表，例如散点图、条形图、气泡图和3D图表等。graph_objects使得创建高度可定制的图表变得轻而易举，对于需要高度自定义图表的使用者来说非常有用。\n","\n","而express则提供了更简单的图表制作方式。它提供了一组方便的方法，可以帮助你快速创建通用的图表，例如线图、柱状图和散点图等。express适合那些希望快速创建美丽图表的用户，它极大地简化了制作图表的过程。\n","\n","# 2.Scipy.stats\n","Scipy.stats是一个用于统计分析的Python库，它包含了各种用于概率分布、假设检验、回归分析和描述统计学等的函数。这些函数被广泛应用于工程、科学和社会学等领域。通过SciPy.stats，你可以进行诸如t检验、卡方检验、F检验等常见的统计分析过程，这对于需要进行数据分析和统计建模的用户来说非常有用。\n","\n","# 3.IPython.display\n","IPython.display是一个用于在Jupyter Notebook中显示内容的Python库。它提供了一组用于在Notebook中显示各种内容的函数，包括文本、图像、HTML和多媒体内容等。IPython.display适合那些希望将复杂的分析结果以可视化方式展现给用户的人。例如，你可以使用它在Notebook中显示某个图表、某个视频或者某个动画等，这可以使得分析结果更加生动形象。"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:25:33.557943Z","iopub.status.busy":"2023-10-11T15:25:33.557353Z","iopub.status.idle":"2023-10-11T15:25:34.878655Z","shell.execute_reply":"2023-10-11T15:25:34.877362Z","shell.execute_reply.started":"2023-10-11T15:25:33.557906Z"},"trusted":true},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.express as px\n","import scipy.stats as stats\n","from IPython.display import display, HTML"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:25:41.000285Z","iopub.status.busy":"2023-10-11T15:25:40.999621Z","iopub.status.idle":"2023-10-11T15:25:41.058103Z","shell.execute_reply":"2023-10-11T15:25:41.056869Z","shell.execute_reply.started":"2023-10-11T15:25:41.000247Z"},"trusted":true},"outputs":[],"source":["#import data\n","df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:25:50.763308Z","iopub.status.busy":"2023-10-11T15:25:50.762677Z","iopub.status.idle":"2023-10-11T15:25:50.825601Z","shell.execute_reply":"2023-10-11T15:25:50.824444Z","shell.execute_reply.started":"2023-10-11T15:25:50.763247Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>MSSubClass</th>\n","      <th>MSZoning</th>\n","      <th>LotFrontage</th>\n","      <th>LotArea</th>\n","      <th>Street</th>\n","      <th>Alley</th>\n","      <th>LotShape</th>\n","      <th>LandContour</th>\n","      <th>Utilities</th>\n","      <th>...</th>\n","      <th>PoolArea</th>\n","      <th>PoolQC</th>\n","      <th>Fence</th>\n","      <th>MiscFeature</th>\n","      <th>MiscVal</th>\n","      <th>MoSold</th>\n","      <th>YrSold</th>\n","      <th>SaleType</th>\n","      <th>SaleCondition</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>65.0</td>\n","      <td>8450</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>208500</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>80.0</td>\n","      <td>9600</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2007</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>181500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>68.0</td>\n","      <td>11250</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>223500</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>70</td>\n","      <td>RL</td>\n","      <td>60.0</td>\n","      <td>9550</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2006</td>\n","      <td>WD</td>\n","      <td>Abnorml</td>\n","      <td>140000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>84.0</td>\n","      <td>14260</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>IR1</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>12</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>250000</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1455</th>\n","      <td>1456</td>\n","      <td>60</td>\n","      <td>RL</td>\n","      <td>62.0</td>\n","      <td>7917</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>2007</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>175000</td>\n","    </tr>\n","    <tr>\n","      <th>1456</th>\n","      <td>1457</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>85.0</td>\n","      <td>13175</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>MnPrv</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>210000</td>\n","    </tr>\n","    <tr>\n","      <th>1457</th>\n","      <td>1458</td>\n","      <td>70</td>\n","      <td>RL</td>\n","      <td>66.0</td>\n","      <td>9042</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>GdPrv</td>\n","      <td>Shed</td>\n","      <td>2500</td>\n","      <td>5</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>266500</td>\n","    </tr>\n","    <tr>\n","      <th>1458</th>\n","      <td>1459</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>68.0</td>\n","      <td>9717</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>2010</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>142125</td>\n","    </tr>\n","    <tr>\n","      <th>1459</th>\n","      <td>1460</td>\n","      <td>20</td>\n","      <td>RL</td>\n","      <td>75.0</td>\n","      <td>9937</td>\n","      <td>Pave</td>\n","      <td>NaN</td>\n","      <td>Reg</td>\n","      <td>Lvl</td>\n","      <td>AllPub</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>6</td>\n","      <td>2008</td>\n","      <td>WD</td>\n","      <td>Normal</td>\n","      <td>147500</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1460 rows × 81 columns</p>\n","</div>"],"text/plain":["        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n","1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n","2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n","3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n","4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n","...    ...         ...      ...          ...      ...    ...   ...      ...   \n","1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n","1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n","1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n","1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n","1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n","\n","     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n","0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","...          ...       ...  ...      ...    ...    ...         ...     ...   \n","1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n","1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n","1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n","\n","     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n","0         2   2008        WD         Normal     208500  \n","1         5   2007        WD         Normal     181500  \n","2         9   2008        WD         Normal     223500  \n","3         2   2006        WD        Abnorml     140000  \n","4        12   2008        WD         Normal     250000  \n","...     ...    ...       ...            ...        ...  \n","1455      8   2007        WD         Normal     175000  \n","1456      2   2010        WD         Normal     210000  \n","1457      5   2010        WD         Normal     266500  \n","1458      4   2010        WD         Normal     142125  \n","1459      6   2008        WD         Normal     147500  \n","\n","[1460 rows x 81 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:26:17.196186Z","iopub.status.busy":"2023-10-11T15:26:17.195736Z","iopub.status.idle":"2023-10-11T15:26:17.202477Z","shell.execute_reply":"2023-10-11T15:26:17.201407Z","shell.execute_reply.started":"2023-10-11T15:26:17.196154Z"},"trusted":true},"outputs":[],"source":["#Function to create scrollable table within a small window\n","def create_scrollable_table(df, table_id, title):\n","    html = f'<h3>{title}</h3>'\n","    html += f'<div id=\"{table_id}\"style=\"height:200px; overflow:auto;\">'\n","    html += df.to_html()\n","    html += '</div>'\n","    return html"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:26:26.347412Z","iopub.status.busy":"2023-10-11T15:26:26.346958Z","iopub.status.idle":"2023-10-11T15:26:26.441235Z","shell.execute_reply":"2023-10-11T15:26:26.440075Z","shell.execute_reply.started":"2023-10-11T15:26:26.347378Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>MSSubClass</th>\n","      <th>LotFrontage</th>\n","      <th>LotArea</th>\n","      <th>OverallQual</th>\n","      <th>OverallCond</th>\n","      <th>YearBuilt</th>\n","      <th>YearRemodAdd</th>\n","      <th>MasVnrArea</th>\n","      <th>BsmtFinSF1</th>\n","      <th>...</th>\n","      <th>WoodDeckSF</th>\n","      <th>OpenPorchSF</th>\n","      <th>EnclosedPorch</th>\n","      <th>3SsnPorch</th>\n","      <th>ScreenPorch</th>\n","      <th>PoolArea</th>\n","      <th>MiscVal</th>\n","      <th>MoSold</th>\n","      <th>YrSold</th>\n","      <th>SalePrice</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1201.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1452.000000</td>\n","      <td>1460.000000</td>\n","      <td>...</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","      <td>1460.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>730.500000</td>\n","      <td>56.897260</td>\n","      <td>70.049958</td>\n","      <td>10516.828082</td>\n","      <td>6.099315</td>\n","      <td>5.575342</td>\n","      <td>1971.267808</td>\n","      <td>1984.865753</td>\n","      <td>103.685262</td>\n","      <td>443.639726</td>\n","      <td>...</td>\n","      <td>94.244521</td>\n","      <td>46.660274</td>\n","      <td>21.954110</td>\n","      <td>3.409589</td>\n","      <td>15.060959</td>\n","      <td>2.758904</td>\n","      <td>43.489041</td>\n","      <td>6.321918</td>\n","      <td>2007.815753</td>\n","      <td>180921.195890</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>421.610009</td>\n","      <td>42.300571</td>\n","      <td>24.284752</td>\n","      <td>9981.264932</td>\n","      <td>1.382997</td>\n","      <td>1.112799</td>\n","      <td>30.202904</td>\n","      <td>20.645407</td>\n","      <td>181.066207</td>\n","      <td>456.098091</td>\n","      <td>...</td>\n","      <td>125.338794</td>\n","      <td>66.256028</td>\n","      <td>61.119149</td>\n","      <td>29.317331</td>\n","      <td>55.757415</td>\n","      <td>40.177307</td>\n","      <td>496.123024</td>\n","      <td>2.703626</td>\n","      <td>1.328095</td>\n","      <td>79442.502883</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>20.000000</td>\n","      <td>21.000000</td>\n","      <td>1300.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1872.000000</td>\n","      <td>1950.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>2006.000000</td>\n","      <td>34900.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>365.750000</td>\n","      <td>20.000000</td>\n","      <td>59.000000</td>\n","      <td>7553.500000</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>1954.000000</td>\n","      <td>1967.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>5.000000</td>\n","      <td>2007.000000</td>\n","      <td>129975.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>730.500000</td>\n","      <td>50.000000</td>\n","      <td>69.000000</td>\n","      <td>9478.500000</td>\n","      <td>6.000000</td>\n","      <td>5.000000</td>\n","      <td>1973.000000</td>\n","      <td>1994.000000</td>\n","      <td>0.000000</td>\n","      <td>383.500000</td>\n","      <td>...</td>\n","      <td>0.000000</td>\n","      <td>25.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>6.000000</td>\n","      <td>2008.000000</td>\n","      <td>163000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1095.250000</td>\n","      <td>70.000000</td>\n","      <td>80.000000</td>\n","      <td>11601.500000</td>\n","      <td>7.000000</td>\n","      <td>6.000000</td>\n","      <td>2000.000000</td>\n","      <td>2004.000000</td>\n","      <td>166.000000</td>\n","      <td>712.250000</td>\n","      <td>...</td>\n","      <td>168.000000</td>\n","      <td>68.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>8.000000</td>\n","      <td>2009.000000</td>\n","      <td>214000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1460.000000</td>\n","      <td>190.000000</td>\n","      <td>313.000000</td>\n","      <td>215245.000000</td>\n","      <td>10.000000</td>\n","      <td>9.000000</td>\n","      <td>2010.000000</td>\n","      <td>2010.000000</td>\n","      <td>1600.000000</td>\n","      <td>5644.000000</td>\n","      <td>...</td>\n","      <td>857.000000</td>\n","      <td>547.000000</td>\n","      <td>552.000000</td>\n","      <td>508.000000</td>\n","      <td>480.000000</td>\n","      <td>738.000000</td>\n","      <td>15500.000000</td>\n","      <td>12.000000</td>\n","      <td>2010.000000</td>\n","      <td>755000.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8 rows × 38 columns</p>\n","</div>"],"text/plain":["                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n","count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n","mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n","std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n","min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n","25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n","50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n","75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n","max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n","\n","       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n","count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n","mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n","std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n","min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n","25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n","50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n","75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n","max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n","\n","        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n","count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n","mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n","std     125.338794    66.256028      61.119149    29.317331    55.757415   \n","min       0.000000     0.000000       0.000000     0.000000     0.000000   \n","25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n","50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n","75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n","max     857.000000   547.000000     552.000000   508.000000   480.000000   \n","\n","          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n","count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n","mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n","std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n","min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n","25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n","50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n","75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n","max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n","\n","[8 rows x 38 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["numerical_features = df.select_dtypes(include=[np.number])\n","numerical_features.describe()"]},{"cell_type":"markdown","metadata":{},"source":["  select_dtypes(include=[np.number])这一部分使用了include参数来选择数据框中的数值型特征。np.number代表numpy库中的数值类型。通过这个操作，numerical_features将会是一个只包括**数值型**特征的子集。\n","  \n","  .describe()函数应用在numerical_features上，用于生成描述性统计信息。describe()默认会计算每列数据的统计指标，包括计数、均值、标准差、最小值、25%分位数、中位数(50%分位数)、75%分位数和最大值。这些统计指标可以帮助你了解**每个数值型特征的分布情况、中心趋势和离散程度**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:30:14.436567Z","iopub.status.busy":"2023-10-11T15:30:14.436134Z","iopub.status.idle":"2023-10-11T15:30:14.525200Z","shell.execute_reply":"2023-10-11T15:30:14.524230Z","shell.execute_reply.started":"2023-10-11T15:30:14.436535Z"},"trusted":true},"outputs":[{"data":{"text/html":["<h3>Summary statistics for numerical features</h3><div id=\"numerical_features\"style=\"height:200px; overflow:auto;\"><table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>mean</th>\n","      <th>std</th>\n","      <th>min</th>\n","      <th>25%</th>\n","      <th>50%</th>\n","      <th>75%</th>\n","      <th>max</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Id</th>\n","      <td>1460.0</td>\n","      <td>730.500000</td>\n","      <td>421.610009</td>\n","      <td>1.0</td>\n","      <td>365.75</td>\n","      <td>730.5</td>\n","      <td>1095.25</td>\n","      <td>1460.0</td>\n","    </tr>\n","    <tr>\n","      <th>MSSubClass</th>\n","      <td>1460.0</td>\n","      <td>56.897260</td>\n","      <td>42.300571</td>\n","      <td>20.0</td>\n","      <td>20.00</td>\n","      <td>50.0</td>\n","      <td>70.00</td>\n","      <td>190.0</td>\n","    </tr>\n","    <tr>\n","      <th>LotFrontage</th>\n","      <td>1201.0</td>\n","      <td>70.049958</td>\n","      <td>24.284752</td>\n","      <td>21.0</td>\n","      <td>59.00</td>\n","      <td>69.0</td>\n","      <td>80.00</td>\n","      <td>313.0</td>\n","    </tr>\n","    <tr>\n","      <th>LotArea</th>\n","      <td>1460.0</td>\n","      <td>10516.828082</td>\n","      <td>9981.264932</td>\n","      <td>1300.0</td>\n","      <td>7553.50</td>\n","      <td>9478.5</td>\n","      <td>11601.50</td>\n","      <td>215245.0</td>\n","    </tr>\n","    <tr>\n","      <th>OverallQual</th>\n","      <td>1460.0</td>\n","      <td>6.099315</td>\n","      <td>1.382997</td>\n","      <td>1.0</td>\n","      <td>5.00</td>\n","      <td>6.0</td>\n","      <td>7.00</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>OverallCond</th>\n","      <td>1460.0</td>\n","      <td>5.575342</td>\n","      <td>1.112799</td>\n","      <td>1.0</td>\n","      <td>5.00</td>\n","      <td>5.0</td>\n","      <td>6.00</td>\n","      <td>9.0</td>\n","    </tr>\n","    <tr>\n","      <th>YearBuilt</th>\n","      <td>1460.0</td>\n","      <td>1971.267808</td>\n","      <td>30.202904</td>\n","      <td>1872.0</td>\n","      <td>1954.00</td>\n","      <td>1973.0</td>\n","      <td>2000.00</td>\n","      <td>2010.0</td>\n","    </tr>\n","    <tr>\n","      <th>YearRemodAdd</th>\n","      <td>1460.0</td>\n","      <td>1984.865753</td>\n","      <td>20.645407</td>\n","      <td>1950.0</td>\n","      <td>1967.00</td>\n","      <td>1994.0</td>\n","      <td>2004.00</td>\n","      <td>2010.0</td>\n","    </tr>\n","    <tr>\n","      <th>MasVnrArea</th>\n","      <td>1452.0</td>\n","      <td>103.685262</td>\n","      <td>181.066207</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>166.00</td>\n","      <td>1600.0</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtFinSF1</th>\n","      <td>1460.0</td>\n","      <td>443.639726</td>\n","      <td>456.098091</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>383.5</td>\n","      <td>712.25</td>\n","      <td>5644.0</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtFinSF2</th>\n","      <td>1460.0</td>\n","      <td>46.549315</td>\n","      <td>161.319273</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>1474.0</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtUnfSF</th>\n","      <td>1460.0</td>\n","      <td>567.240411</td>\n","      <td>441.866955</td>\n","      <td>0.0</td>\n","      <td>223.00</td>\n","      <td>477.5</td>\n","      <td>808.00</td>\n","      <td>2336.0</td>\n","    </tr>\n","    <tr>\n","      <th>TotalBsmtSF</th>\n","      <td>1460.0</td>\n","      <td>1057.429452</td>\n","      <td>438.705324</td>\n","      <td>0.0</td>\n","      <td>795.75</td>\n","      <td>991.5</td>\n","      <td>1298.25</td>\n","      <td>6110.0</td>\n","    </tr>\n","    <tr>\n","      <th>1stFlrSF</th>\n","      <td>1460.0</td>\n","      <td>1162.626712</td>\n","      <td>386.587738</td>\n","      <td>334.0</td>\n","      <td>882.00</td>\n","      <td>1087.0</td>\n","      <td>1391.25</td>\n","      <td>4692.0</td>\n","    </tr>\n","    <tr>\n","      <th>2ndFlrSF</th>\n","      <td>1460.0</td>\n","      <td>346.992466</td>\n","      <td>436.528436</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>728.00</td>\n","      <td>2065.0</td>\n","    </tr>\n","    <tr>\n","      <th>LowQualFinSF</th>\n","      <td>1460.0</td>\n","      <td>5.844521</td>\n","      <td>48.623081</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>572.0</td>\n","    </tr>\n","    <tr>\n","      <th>GrLivArea</th>\n","      <td>1460.0</td>\n","      <td>1515.463699</td>\n","      <td>525.480383</td>\n","      <td>334.0</td>\n","      <td>1129.50</td>\n","      <td>1464.0</td>\n","      <td>1776.75</td>\n","      <td>5642.0</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtFullBath</th>\n","      <td>1460.0</td>\n","      <td>0.425342</td>\n","      <td>0.518911</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtHalfBath</th>\n","      <td>1460.0</td>\n","      <td>0.057534</td>\n","      <td>0.238753</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>FullBath</th>\n","      <td>1460.0</td>\n","      <td>1.565068</td>\n","      <td>0.550916</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>2.0</td>\n","      <td>2.00</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>HalfBath</th>\n","      <td>1460.0</td>\n","      <td>0.382877</td>\n","      <td>0.502885</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>BedroomAbvGr</th>\n","      <td>1460.0</td>\n","      <td>2.866438</td>\n","      <td>0.815778</td>\n","      <td>0.0</td>\n","      <td>2.00</td>\n","      <td>3.0</td>\n","      <td>3.00</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>KitchenAbvGr</th>\n","      <td>1460.0</td>\n","      <td>1.046575</td>\n","      <td>0.220338</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>1.0</td>\n","      <td>1.00</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>TotRmsAbvGrd</th>\n","      <td>1460.0</td>\n","      <td>6.517808</td>\n","      <td>1.625393</td>\n","      <td>2.0</td>\n","      <td>5.00</td>\n","      <td>6.0</td>\n","      <td>7.00</td>\n","      <td>14.0</td>\n","    </tr>\n","    <tr>\n","      <th>Fireplaces</th>\n","      <td>1460.0</td>\n","      <td>0.613014</td>\n","      <td>0.644666</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>1.0</td>\n","      <td>1.00</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>GarageYrBlt</th>\n","      <td>1379.0</td>\n","      <td>1978.506164</td>\n","      <td>24.689725</td>\n","      <td>1900.0</td>\n","      <td>1961.00</td>\n","      <td>1980.0</td>\n","      <td>2002.00</td>\n","      <td>2010.0</td>\n","    </tr>\n","    <tr>\n","      <th>GarageCars</th>\n","      <td>1460.0</td>\n","      <td>1.767123</td>\n","      <td>0.747315</td>\n","      <td>0.0</td>\n","      <td>1.00</td>\n","      <td>2.0</td>\n","      <td>2.00</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>GarageArea</th>\n","      <td>1460.0</td>\n","      <td>472.980137</td>\n","      <td>213.804841</td>\n","      <td>0.0</td>\n","      <td>334.50</td>\n","      <td>480.0</td>\n","      <td>576.00</td>\n","      <td>1418.0</td>\n","    </tr>\n","    <tr>\n","      <th>WoodDeckSF</th>\n","      <td>1460.0</td>\n","      <td>94.244521</td>\n","      <td>125.338794</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>168.00</td>\n","      <td>857.0</td>\n","    </tr>\n","    <tr>\n","      <th>OpenPorchSF</th>\n","      <td>1460.0</td>\n","      <td>46.660274</td>\n","      <td>66.256028</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>25.0</td>\n","      <td>68.00</td>\n","      <td>547.0</td>\n","    </tr>\n","    <tr>\n","      <th>EnclosedPorch</th>\n","      <td>1460.0</td>\n","      <td>21.954110</td>\n","      <td>61.119149</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>552.0</td>\n","    </tr>\n","    <tr>\n","      <th>3SsnPorch</th>\n","      <td>1460.0</td>\n","      <td>3.409589</td>\n","      <td>29.317331</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>508.0</td>\n","    </tr>\n","    <tr>\n","      <th>ScreenPorch</th>\n","      <td>1460.0</td>\n","      <td>15.060959</td>\n","      <td>55.757415</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>480.0</td>\n","    </tr>\n","    <tr>\n","      <th>PoolArea</th>\n","      <td>1460.0</td>\n","      <td>2.758904</td>\n","      <td>40.177307</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>738.0</td>\n","    </tr>\n","    <tr>\n","      <th>MiscVal</th>\n","      <td>1460.0</td>\n","      <td>43.489041</td>\n","      <td>496.123024</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>0.0</td>\n","      <td>0.00</td>\n","      <td>15500.0</td>\n","    </tr>\n","    <tr>\n","      <th>MoSold</th>\n","      <td>1460.0</td>\n","      <td>6.321918</td>\n","      <td>2.703626</td>\n","      <td>1.0</td>\n","      <td>5.00</td>\n","      <td>6.0</td>\n","      <td>8.00</td>\n","      <td>12.0</td>\n","    </tr>\n","    <tr>\n","      <th>YrSold</th>\n","      <td>1460.0</td>\n","      <td>2007.815753</td>\n","      <td>1.328095</td>\n","      <td>2006.0</td>\n","      <td>2007.00</td>\n","      <td>2008.0</td>\n","      <td>2009.00</td>\n","      <td>2010.0</td>\n","    </tr>\n","    <tr>\n","      <th>SalePrice</th>\n","      <td>1460.0</td>\n","      <td>180921.195890</td>\n","      <td>79442.502883</td>\n","      <td>34900.0</td>\n","      <td>129975.00</td>\n","      <td>163000.0</td>\n","      <td>214000.00</td>\n","      <td>755000.0</td>\n","    </tr>\n","  </tbody>\n","</table></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["#Summary statistics for numerical features\n","summary_stats = numerical_features.describe().T\n","html_numerical = create_scrollable_table(summary_stats, 'numerical_features', 'Summary statistics for numerical features')\n","display(HTML(html_numerical))"]},{"cell_type":"markdown","metadata":{},"source":["describe().T被应用在numerical_features上，生成了数值型特征的描述性统计信息。.T表示对结果进行转置操作，使得每个特征在行上，统计指标在列上。\n","\n","create_scrollable_table是一个自定义函数，用于创建可滚动的表格。它接受三个参数：描述性统计结果（summary_stats）、表格标题（'numerical_features'）和表格描述（'Summary statistics for numerical features'）。它会生成一个含有滚动功能的HTML表格。\n","\n","display(HTML(html_numerical))的作用是显示生成的HTML表格，其中html_numerical包含了表格的相关HTML代码。"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T15:29:27.749404Z","iopub.status.busy":"2023-10-11T15:29:27.748955Z","iopub.status.idle":"2023-10-11T15:29:27.830383Z","shell.execute_reply":"2023-10-11T15:29:27.829184Z","shell.execute_reply.started":"2023-10-11T15:29:27.749369Z"},"trusted":true},"outputs":[{"data":{"text/html":["<h3>Summary statistics for categorical</h3><div id=\"categorical_features\"style=\"height:200px; overflow:auto;\"><table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>unique</th>\n","      <th>top</th>\n","      <th>freq</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>MSZoning</th>\n","      <td>1460</td>\n","      <td>5</td>\n","      <td>RL</td>\n","      <td>1151</td>\n","    </tr>\n","    <tr>\n","      <th>Street</th>\n","      <td>1460</td>\n","      <td>2</td>\n","      <td>Pave</td>\n","      <td>1454</td>\n","    </tr>\n","    <tr>\n","      <th>Alley</th>\n","      <td>91</td>\n","      <td>2</td>\n","      <td>Grvl</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>LotShape</th>\n","      <td>1460</td>\n","      <td>4</td>\n","      <td>Reg</td>\n","      <td>925</td>\n","    </tr>\n","    <tr>\n","      <th>LandContour</th>\n","      <td>1460</td>\n","      <td>4</td>\n","      <td>Lvl</td>\n","      <td>1311</td>\n","    </tr>\n","    <tr>\n","      <th>Utilities</th>\n","      <td>1460</td>\n","      <td>2</td>\n","      <td>AllPub</td>\n","      <td>1459</td>\n","    </tr>\n","    <tr>\n","      <th>LotConfig</th>\n","      <td>1460</td>\n","      <td>5</td>\n","      <td>Inside</td>\n","      <td>1052</td>\n","    </tr>\n","    <tr>\n","      <th>LandSlope</th>\n","      <td>1460</td>\n","      <td>3</td>\n","      <td>Gtl</td>\n","      <td>1382</td>\n","    </tr>\n","    <tr>\n","      <th>Neighborhood</th>\n","      <td>1460</td>\n","      <td>25</td>\n","      <td>NAmes</td>\n","      <td>225</td>\n","    </tr>\n","    <tr>\n","      <th>Condition1</th>\n","      <td>1460</td>\n","      <td>9</td>\n","      <td>Norm</td>\n","      <td>1260</td>\n","    </tr>\n","    <tr>\n","      <th>Condition2</th>\n","      <td>1460</td>\n","      <td>8</td>\n","      <td>Norm</td>\n","      <td>1445</td>\n","    </tr>\n","    <tr>\n","      <th>BldgType</th>\n","      <td>1460</td>\n","      <td>5</td>\n","      <td>1Fam</td>\n","      <td>1220</td>\n","    </tr>\n","    <tr>\n","      <th>HouseStyle</th>\n","      <td>1460</td>\n","      <td>8</td>\n","      <td>1Story</td>\n","      <td>726</td>\n","    </tr>\n","    <tr>\n","      <th>RoofStyle</th>\n","      <td>1460</td>\n","      <td>6</td>\n","      <td>Gable</td>\n","      <td>1141</td>\n","    </tr>\n","    <tr>\n","      <th>RoofMatl</th>\n","      <td>1460</td>\n","      <td>8</td>\n","      <td>CompShg</td>\n","      <td>1434</td>\n","    </tr>\n","    <tr>\n","      <th>Exterior1st</th>\n","      <td>1460</td>\n","      <td>15</td>\n","      <td>VinylSd</td>\n","      <td>515</td>\n","    </tr>\n","    <tr>\n","      <th>Exterior2nd</th>\n","      <td>1460</td>\n","      <td>16</td>\n","      <td>VinylSd</td>\n","      <td>504</td>\n","    </tr>\n","    <tr>\n","      <th>MasVnrType</th>\n","      <td>588</td>\n","      <td>3</td>\n","      <td>BrkFace</td>\n","      <td>445</td>\n","    </tr>\n","    <tr>\n","      <th>ExterQual</th>\n","      <td>1460</td>\n","      <td>4</td>\n","      <td>TA</td>\n","      <td>906</td>\n","    </tr>\n","    <tr>\n","      <th>ExterCond</th>\n","      <td>1460</td>\n","      <td>5</td>\n","      <td>TA</td>\n","      <td>1282</td>\n","    </tr>\n","    <tr>\n","      <th>Foundation</th>\n","      <td>1460</td>\n","      <td>6</td>\n","      <td>PConc</td>\n","      <td>647</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtQual</th>\n","      <td>1423</td>\n","      <td>4</td>\n","      <td>TA</td>\n","      <td>649</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtCond</th>\n","      <td>1423</td>\n","      <td>4</td>\n","      <td>TA</td>\n","      <td>1311</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtExposure</th>\n","      <td>1422</td>\n","      <td>4</td>\n","      <td>No</td>\n","      <td>953</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtFinType1</th>\n","      <td>1423</td>\n","      <td>6</td>\n","      <td>Unf</td>\n","      <td>430</td>\n","    </tr>\n","    <tr>\n","      <th>BsmtFinType2</th>\n","      <td>1422</td>\n","      <td>6</td>\n","      <td>Unf</td>\n","      <td>1256</td>\n","    </tr>\n","    <tr>\n","      <th>Heating</th>\n","      <td>1460</td>\n","      <td>6</td>\n","      <td>GasA</td>\n","      <td>1428</td>\n","    </tr>\n","    <tr>\n","      <th>HeatingQC</th>\n","      <td>1460</td>\n","      <td>5</td>\n","      <td>Ex</td>\n","      <td>741</td>\n","    </tr>\n","    <tr>\n","      <th>CentralAir</th>\n","      <td>1460</td>\n","      <td>2</td>\n","      <td>Y</td>\n","      <td>1365</td>\n","    </tr>\n","    <tr>\n","      <th>Electrical</th>\n","      <td>1459</td>\n","      <td>5</td>\n","      <td>SBrkr</td>\n","      <td>1334</td>\n","    </tr>\n","    <tr>\n","      <th>KitchenQual</th>\n","      <td>1460</td>\n","      <td>4</td>\n","      <td>TA</td>\n","      <td>735</td>\n","    </tr>\n","    <tr>\n","      <th>Functional</th>\n","      <td>1460</td>\n","      <td>7</td>\n","      <td>Typ</td>\n","      <td>1360</td>\n","    </tr>\n","    <tr>\n","      <th>FireplaceQu</th>\n","      <td>770</td>\n","      <td>5</td>\n","      <td>Gd</td>\n","      <td>380</td>\n","    </tr>\n","    <tr>\n","      <th>GarageType</th>\n","      <td>1379</td>\n","      <td>6</td>\n","      <td>Attchd</td>\n","      <td>870</td>\n","    </tr>\n","    <tr>\n","      <th>GarageFinish</th>\n","      <td>1379</td>\n","      <td>3</td>\n","      <td>Unf</td>\n","      <td>605</td>\n","    </tr>\n","    <tr>\n","      <th>GarageQual</th>\n","      <td>1379</td>\n","      <td>5</td>\n","      <td>TA</td>\n","      <td>1311</td>\n","    </tr>\n","    <tr>\n","      <th>GarageCond</th>\n","      <td>1379</td>\n","      <td>5</td>\n","      <td>TA</td>\n","      <td>1326</td>\n","    </tr>\n","    <tr>\n","      <th>PavedDrive</th>\n","      <td>1460</td>\n","      <td>3</td>\n","      <td>Y</td>\n","      <td>1340</td>\n","    </tr>\n","    <tr>\n","      <th>PoolQC</th>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>Gd</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>Fence</th>\n","      <td>281</td>\n","      <td>4</td>\n","      <td>MnPrv</td>\n","      <td>157</td>\n","    </tr>\n","    <tr>\n","      <th>MiscFeature</th>\n","      <td>54</td>\n","      <td>4</td>\n","      <td>Shed</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>SaleType</th>\n","      <td>1460</td>\n","      <td>9</td>\n","      <td>WD</td>\n","      <td>1267</td>\n","    </tr>\n","    <tr>\n","      <th>SaleCondition</th>\n","      <td>1460</td>\n","      <td>6</td>\n","      <td>Normal</td>\n","      <td>1198</td>\n","    </tr>\n","  </tbody>\n","</table></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["#Summary statistics for categorical features\n","categorical_features = df.select_dtypes(include=[object])\n","cat_summary_stats = categorical_features.describe().T\n","html_categorical = create_scrollable_table(cat_summary_stats, 'categorical_features',\n","                                         'Summary statistics for categorical')\n","display(HTML(html_categorical))"]},{"cell_type":"markdown","metadata":{},"source":["  select_dtypes(include=[object])这一部分使用了include参数来选择数据框(df)中的分类特征。object表示Python中的字符串类型，通常用于表示**分类变量**。通过这个操作，categorical_features将会是一个只包括**分类特征**的子集。\n","  \n","  .describe().T函数被应用在categorical_features上，生成了分类特征的描述性统计信息。.T表示对结果进行转置操作，使得每个特征在行上，统计指标在列上"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:17.688778Z","iopub.status.busy":"2023-10-10T10:05:17.688584Z","iopub.status.idle":"2023-10-10T10:05:17.708502Z","shell.execute_reply":"2023-10-10T10:05:17.707563Z","shell.execute_reply.started":"2023-10-10T10:05:17.688761Z"},"trusted":true},"outputs":[],"source":["#Null values in the dataset\n","null_values = df.isnull().sum()\n","html_null_values = create_scrollable_table(null_values.to_frame(), 'null values',\n","                                          'Null values in the dataset')\n","\n","#Percentage of missing values for each feature\n","missing_percentage = (df.isnull().sum()/len(df)) * 100\n","html_missing_percentage = create_scrollable_table(missing_percentage.to_frame(),\n","                                                 'missing_percentage',\n","                                                 'Percentage of missing')\n","display(HTML(html_null_values + html_missing_percentage))"]},{"cell_type":"markdown","metadata":{},"source":["isnull().sum()函数被应用在数据框(df)上，返回每个特征中缺失值的数量。这是一个Series对象，其中每个特征都被视为索引，其值为该特征的缺失值数量。\n","\n","to_frame()函数被应用在null_values上，将其转换为DataFrame对象。\n","\n","(df.isnull().sum()/len(df)) * 100计算每个特征中缺失值的百分比，生成了每个特征中缺失值的百分比信息\n","\n","to_frame()函数被应用在missing_percentage上，将其转换为DataFrame对象。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:17.713916Z","iopub.status.busy":"2023-10-10T10:05:17.713032Z","iopub.status.idle":"2023-10-10T10:05:17.740227Z","shell.execute_reply":"2023-10-10T10:05:17.739410Z","shell.execute_reply.started":"2023-10-10T10:05:17.713834Z"},"trusted":true},"outputs":[],"source":["#Exploring rows with missing values\n","rows_with_missing_values = df[df.isnull().any(axis=1)]\n","html_rows_with_missing_values = create_scrollable_table(rows_with_missing_values.head(),\n","                                                 'rows_with_missing_values',\n","                                                 'Rows with missing values')\n","display(HTML(html_rows_with_missing_values))"]},{"cell_type":"markdown","metadata":{},"source":["df.isnull().any(axis=1)函数被应用在数据框(df)上，返回一个布尔Series对象，表示每一列是否存在缺失值。any(axis=1)的参数设置为1，表示沿着列的方向检查是否有任何一个元素为真（即是否存在缺失值）\n","\n","df[df.isnull().any(axis=1)]将会筛选出数据集中存在缺失值的列，返回一个新的数据框，其中只包含具有缺失值的列\n","\n","head()函数被应用在rows_with_missing_values上，返回新数据框中的前几行，默认为5行"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:17.741989Z","iopub.status.busy":"2023-10-10T10:05:17.741303Z","iopub.status.idle":"2023-10-10T10:05:17.747941Z","shell.execute_reply":"2023-10-10T10:05:17.747297Z","shell.execute_reply.started":"2023-10-10T10:05:17.741969Z"},"trusted":true},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:17.749401Z","iopub.status.busy":"2023-10-10T10:05:17.748950Z","iopub.status.idle":"2023-10-10T10:05:19.602507Z","shell.execute_reply":"2023-10-10T10:05:19.601718Z","shell.execute_reply.started":"2023-10-10T10:05:17.749378Z"},"trusted":true},"outputs":[],"source":["# Fit a normal distribution to the SalePrice data\n","mu, sigma = stats.norm.fit(df['SalePrice'])\n","\n","#Create a histogram of the ScalePrice columns\n","hist_data = go.Histogram(x=df['SalePrice'],nbinsx=50,name='Histogram',opacity=0.75,\n","                              histnorm='probability density',marker=dict(color='purple'))\n","\n","#Calculate the normal distribution based on the fitted parameters\n","x_norm = np.linspace(df['SalePrice'].min(), df['SalePrice'].max(), 100)\n","y_norm = stats.norm.pdf(x_norm, mu, sigma)\n","\n","#Create the normal distribution overlay\n","norm_data = go.Scatter(x=x_norm, y=y_norm, mode='lines', name=f\"Normal dist. (µ={mu:.2f}, σ={sigma:.2f})\", line=dict(color=\"green\"))\n","\n","#Create the normal distribution overlay\n","fig = go.Figure(data=[hist_data, norm_data])\n","\n","#Set the layout for the plot\n","fig.update_layout(title=\"SalePrice Distribution\",\n","                 xaxis_title='SalePrice',\n","                 yaxis_title='Density',\n","                 legend_title_text='Fitted Normal Distribution',\n","                 plot_bgcolor='rgba(32,32,32,1)',\n","                 paper_bgcolor='rgba(32,32,32,1)',\n","                 font=dict(color='white')\n","                 )\n"]},{"cell_type":"markdown","metadata":{},"source":["#Fit a normal distribution to the SalePrice data\n","\n","  通过stats.norm.fit()函数来对df['SalePrice']列进行正态分布拟合，返回拟合后分布的均值和标准差，即mu和sigma\n","\n","#Create a histogram of the ScalePrice columns\n","\n","  使用go.Histogram()函数创建一个直方图，其中x参数为要画直方图的数据列（这里是df['SalePrice']），nbinsx表示直方图的条数，histnorm='probability density'参数表示要以概率密度函数的形式画出直方图，opacity表示图表的透明度，name是该直方图在图例中显示的名称，marker参数可用于设置图表的颜色、大小等。\n","\n","#Calculate the normal distribution based on the fitted parameters\n","\n","  通过np.linspace()函数生成一组等间隔的数字，作为横坐标。使用stats.norm.pdf()函数计算在这组数字上的正态分布的概率密度函数值，并将其存储到y_norm变量中\n","\n","#Create the normal distribution overlay\n","\n","  使用go.Scatter()函数创建一个散点图，其中x参数为之前生成的等间隔数字，y参数为计算得到的概率密度函数值，mode='lines'表示要以线条的形式绘制，name是该线条在图例中显示的名称，line参数可用于设置线条的颜色、宽度等\n","\n","#Create the normal distribution overlay\n","\n","  go.Figure()函数将直方图和概率密度函数图合并成一个图表，并将其存储到fig变量中\n","\n","#Set the layout for the plot\n","\n","  fig.update_layout()函数用于更新图表的布局。title参数设置图表的标题为\"SalePrice Distribution\"，xaxis_title参数设置横坐标的标签为\"SalePrice\"，yaxis_title参数设置纵坐标的标签为\"Density\"，legend_title_text参数设置图例标题为\"Fitted Normal Distribution\"。\n","\n","  plot_bgcolor参数和paper_bgcolor参数分别设置图表的绘图区域和整个图表的背景颜色为黑色（RGBA颜色表示为\"rgba(32,32,32,1)\"）。font参数设置图表中文本的颜色为白色。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Create a Q-Q plot\n","qq_data = stats.probplot(df['SalePrice'], dist='norm')\n","qq_fig = px.scatter(x=qq_data[0][0], y=qq_data[0][1], labels={'x': 'Theoretical Quantiles', 'y':'Ordered Values'}, color_discrete_sequence=['purple'])\n","qq_fig.update_layout(title='Q-Q plot',\n","                    plot_bgcolor='rgba(32, 32, 32, 1)',\n","                    paper_bgcolor='rgba(32, 32, 32, 1)',\n","                    font=dict(color='white')\n","                    )\n","\n","#Calculate the line of best fit\n","slope, intercept, r_value, p_value, std_err = stats.linregress(qq_data[0][0], qq_data[0][1])\n","line_x = np.array(qq_data[0][0])\n","line_y = intercept + slope * line_x\n","\n","#Add the line of beat fit to the Q-Q plot\n","line_data = go.Scatter(x=line_x, y=line_y, mode='lines', name='Normal Line', line=dict(color='green'))\n","\n","#Update the Q-Q plot with the normal line\n","qq_fig.add_trace(line_data)\n","\n","#Show the plots\n","fig.show()\n","qq_fig.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["stats.probplot()函数用于生成Q-Q plot。其中，df['SalePrice']作为输入数据，dist='norm'参数表示使用正态分布作为比较标准。\n","\n","px.scatter()函数用于生成散点图，其中x参数为理论量化值，y参数为排序后的实际值。此外，labels参数用于设置x轴和y轴的标签，color_discrete_sequence参数可用于设置散点图的颜色。\n","\n","使用stats.linregress()函数计算适合数据的最佳拟合直线，然后使用go.Scatter()函数生成该直线的散点图，并将其添加到原始Q-Q plot图表中，再次使用update_layout()函数对图表进行设置，并使用qq_fig.show()显示结果\n","\n","通过以上步骤，可以更多地了解数据与正态分布的偏离程度，并验证该数据是否符合正态分布。\n","\n","在生成Q-Q plot时，我们将实际观测值的排序顺序（即横坐标）与对应的理论量化值的排序顺序（即纵坐标）进行比较。如果数据符合所选择的分布函数，则这些点应该沿着一条直线分布。如果数据偏离了这条直线，则可能表明数据可能不符合所选择的分布函数。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:19.604511Z","iopub.status.busy":"2023-10-10T10:05:19.603668Z","iopub.status.idle":"2023-10-10T10:05:19.652713Z","shell.execute_reply":"2023-10-10T10:05:19.651826Z","shell.execute_reply.started":"2023-10-10T10:05:19.604475Z"},"trusted":true},"outputs":[],"source":["#1.Distribution of dwelling types and relation to saleprices\n","dwelling_types = df['BldgType'].value_counts()\n","dwelling_prices = df.groupby('BldgType')['SalePrice'].mean()\n","\n","#Format labels for the second graph\n","formatted_dwelling_prices = ['$' + f'{value:,.2f}' for value in dwelling_prices.values]\n","\n","#Create bar charts\n","fig1 = go.Figure(data=[go.Bar(x=dwelling_types.index,\n","                             y=dwelling_types.values,\n","                             marker_color='rgb(76,175,80)',\n","                             text=dwelling_types.values,\n","                             textposition='outside',\n","                             width=0.4,\n","                             marker=dict(line=dict(width=2, color='rgba(0,0,0,1)'),opacity=1)\n","                             )])\n","fig1.update_layout(title='Distribution of Building Types',\n","                  xaxis_title='Buliding Type',\n","                  yaxis_title='Count',\n","                  plot_bgcolor='rgba(34, 34, 34, 1)',\n","                  paper_bgcolor='rgba(34, 34, 34, 1)',\n","                  font=dict(color='white')\n","                  )\n","fig2 = go.Figure(data=[go.Bar(x=dwelling_prices.index,\n","                             y=dwelling_prices.values,\n","                             marker_color='rgb(156,39,176)',\n","                             text=formatted_dwelling_prices,\n","                             textposition='outside',\n","                             width=0.4,\n","                             marker=dict(line=dict(width=2, color='rgba(0,0,0,1)'),opacity=1)\n","                             )])\n","fig2.update_layout(title='Average Sale Price by Building Type',\n","                  xaxis_title='Building Type',\n","                  yaxis_title='Price',\n","                  plot_bgcolor='rgba(34,34,34,1)',\n","                  paper_bgcolor='rgba(34,34,34,1)',\n","                  font=dict(color='white')\n","                  )\n","#show the figures\n","fig1.show()\n","fig2.show()"]},{"cell_type":"markdown","metadata":{},"source":["对DataFrame中'BldgType'列的值进行计数，并将计数结果存储在'dwelling_types'变量中。它会统计每种建筑类型出现的次数。\n","\n","对'DataFrame'根据建筑类型('BldgType')进行分组，然后计算每个建筑类型对应的'SalePrice'列的均值，并将结果存储在'dwelling_prices'变量中。它会得到每个建筑类型的平均销售价格。\n","\n","对'dwelling_prices'中的每个价格值进行格式化，添加货币符号和两位小数，并将格式化后的字符串存储在'formatted_dwelling_prices'列表中。例如，如果一个价格值为100000，它将被格式化为\"$100,000.00\"。\n","\n","创建了一个柱状图对象(fig1)，使用Plotly库的Bar函数。它将建筑类型作为X轴的标签，建筑类型数量作为Y轴的值。通过设置颜色、文字位置、宽度和边框等参数，美化了柱状图的显示效果。\n","\n","设置柱状图(fig1)的布局和样式。它设置了图表的标题、X轴和Y轴的标题，以及图表的背景颜色和字体颜色等。\n","\n","创建了另一个柱状图对象(fig2)，用于展示不同建筑类型的平均销售价格。它的设置与之前的柱状图类似，只是X轴的标签换成了建筑类型的平均销售价格。\n","\n","这行代码用于设置柱状图(fig2)的布局和样式，具体设置与之前的柱状图类似。\n","\n","第一个图表显示了不同建筑类型的数量分布，可以帮助我们了解不同类型房屋的数量占比情况。通过直观地比较柱状图的高度，我们可以得知哪种类型的房屋数量最多，哪些类型的房屋数量较少。\n","\n","第二个图表展示了不同建筑类型的平均销售价格，有助于我们比较各种建筑类型的房屋价格水平。通过柱状图的高度，我们可以直观地了解每种建筑类型的平均销售价格，从而判断哪种类型的房屋价格较高或较低。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:19.655270Z","iopub.status.busy":"2023-10-10T10:05:19.654269Z","iopub.status.idle":"2023-10-10T10:05:19.754242Z","shell.execute_reply":"2023-10-10T10:05:19.752739Z","shell.execute_reply.started":"2023-10-10T10:05:19.655247Z"},"trusted":true},"outputs":[],"source":["#2.Zoning impact on sale price\n","zoning_prices = df.groupby('MSZoning')['SalePrice'].mean()\n","fig3 = px.bar(x=zoning_prices.index, y=zoning_prices.values,\n","             title='Averge Sale Price by Zoning',\n","             color_discrete_sequence=['purple', 'green'],text=zoning_prices.values,\n","             template='plotly_dark')\n","fig3.update_traces(texttemplate='$%{text:,.0f}',textposition='outside')\n","fig3.update_yaxes(title='Sale Price', tickprefix='$', tickformat=',')\n","fig3.update_xaxes(title='Zoning')\n","fig3.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n","\n","fig3.show()"]},{"cell_type":"markdown","metadata":{},"source":["将数据集 df 按照 MSZoning 分组，并计算每个分组中 SalePrice 的平均值，得到一个名为 zoning_prices 的 Pandas Series。\n","\n","使用 plotly.express 库创建一个条形图 fig3。x 参数为 zoning_prices.index，即区域名称；y 参数为 zoning_prices.values，即平均房价；title 参数为图表的标题；color_discrete_sequence 参数用于设置颜色序列；text 参数为条形上显示的文本，这里为平均房价的值；template 参数用于指定图表样式模板\n","\n","使用 update_traces() 方法对 fig3 中的每一个条形进行设置，包括设置文本模板、文本位置等。\n","\n","使用 update_yaxes() 和 update_xaxes() 方法分别对 Y 轴和 X 轴进行设置，包括设置坐标轴标题、坐标轴刻度格式等。\n","\n","使用 update_layout() 方法对图表整体进行设置，包括设置均匀文本最小字号和文本模式。\n","\n","这段代码主要是通过使用 Pandas 分组计算数据集中不同区域的平均房价，并使用 Plotly 库绘制条形图展示不同区域的平均房价。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:19.755924Z","iopub.status.busy":"2023-10-10T10:05:19.755597Z","iopub.status.idle":"2023-10-10T10:05:19.855105Z","shell.execute_reply":"2023-10-10T10:05:19.854020Z","shell.execute_reply.started":"2023-10-10T10:05:19.755899Z"},"trusted":true},"outputs":[],"source":["# 3. Street and alley access types effect on sale price\n","street_prices = df.groupby('Street')['SalePrice'].mean()\n","alley_prices = df.groupby('Alley')['SalePrice'].mean()\n","\n","# Street Prices\n","colors_street = np.where(street_prices.index == 'Pave', 'purple', 'green')\n","fig5 = px.bar(x=street_prices.index, y=street_prices.values, title='Average Sale Price by Street Type',\n","              template='plotly_dark', text=street_prices.values,\n","              color=colors_street, color_discrete_sequence=['purple', 'green'])\n","\n","fig5.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')\n","fig5.update_yaxes(title='Sale Price', tickprefix='$', tickformat=',')\n","fig5.update_xaxes(title='Street Type')\n","fig5.update_layout(showlegend=False)\n","\n","# Alley Prices\n","colors_alley = np.where(alley_prices.index == 'Pave', 'purple', 'green')\n","fig6 = px.bar(x=alley_prices.index, y=alley_prices.values, title='Average Sale Price by Alley Type',\n","              template='plotly_dark', text=alley_prices.values,\n","              color=colors_alley, color_discrete_sequence=['purple', 'green'])\n","\n","fig6.update_traces(texttemplate='$%{text:,.0f}', textposition='outside')\n","fig6.update_yaxes(title='Sale Price', tickprefix='$', tickformat=',')\n","fig6.update_xaxes(title='Alley Type')\n","fig6.update_layout(showlegend=False)\n","\n","fig5.show()\n","fig6.show()"]},{"cell_type":"markdown","metadata":{},"source":["使用 Pandas 的 groupby() 方法计算不同街道类型（Street）的平均房价，得到一个名为 street_prices 的 Pandas Series。同样地，使用 groupby() 方法计算不同小巷类型（Alley）的平均房价，得到一个名为 alley_prices 的 Pandas Series。\n","\n","使用 Plotly 库创建两个条形图 fig5 和 fig6。x 参数分别为街道类型和小巷类型；y 参数分别为对应的平均房价；title 参数分别为图表的标题；template 参数用于指定图表样式模板；text 参数为条形上显示的文本，这里为平均房价的值；color 和 color_discrete_sequence 参数用于设置颜色\n","\n","使用 update_traces() 方法对每个图中的条形进行设置，包括设置文本模板和文本位置。\n","\n","使用 update_yaxes() 和 update_xaxes() 方法分别对 Y 轴和 X 轴进行设置，包括设置坐标轴标题、坐标轴刻度格式等。\n","\n","使用 update_layout() 方法对图表整体进行设置，包括隐藏图例。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:19.856499Z","iopub.status.busy":"2023-10-10T10:05:19.856247Z","iopub.status.idle":"2023-10-10T10:05:19.941331Z","shell.execute_reply":"2023-10-10T10:05:19.940043Z","shell.execute_reply.started":"2023-10-10T10:05:19.856479Z"},"trusted":true},"outputs":[],"source":["# 4. Average sale price by property shape\n","colors = px.colors.qualitative.Plotly\n","\n","shape_prices = df.groupby('LotShape')['SalePrice'].mean()\n","contour_prices = df.groupby('LandContour')['SalePrice'].mean()\n","# Shape Prices\n","fig7 = px.bar(x=shape_prices.index, y=shape_prices.values, title='Average Sale Price by Property Shape',\n","              template='plotly_dark', text=shape_prices.values)\n","\n","fig7.update_traces(marker_color=colors, texttemplate='$%{text:,.0f}', textposition='outside')\n","fig7.update_yaxes(title='Sale Price', tickprefix='$', tickformat=',')\n","fig7.update_xaxes(title='Property Shape')\n","fig7.update_layout(showlegend=False)\n","\n","# Contour Prices\n","fig8 = px.bar(x=contour_prices.index, y=contour_prices.values, title='Average Sale Price by Property Contour',\n","              template='plotly_dark', text=contour_prices.values)\n","\n","fig8.update_traces(marker_color=colors, texttemplate='$%{text:,.0f}', textposition='outside')\n","fig8.update_yaxes(title='Sale Price', tickprefix='$', tickformat=',')\n","fig8.update_xaxes(title='Property Contour')\n","fig8.update_layout(showlegend=False)\n","\n","fig7.show()\n","fig8.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:19.942645Z","iopub.status.busy":"2023-10-10T10:05:19.942400Z","iopub.status.idle":"2023-10-10T10:05:20.006085Z","shell.execute_reply":"2023-10-10T10:05:20.005556Z","shell.execute_reply.started":"2023-10-10T10:05:19.942624Z"},"trusted":true},"outputs":[],"source":["# 5. Calculate Property Age\n","df['PropertyAge'] = df['YrSold'] - df['YearBuilt']\n","\n","# Calculate Correlation between Property Age and Sale Price\n","age_price_corr = df['PropertyAge'].corr(df['SalePrice'])\n","print(f'Correlation between Property Age and Sale Price: {age_price_corr}')\n","\n","# Create a scatter plot to visualize the relationship between Property Age and Sale Price\n","fig9 = px.scatter(df, x='PropertyAge', y='SalePrice', title='Property Age vs Sale Price', color='PropertyAge', color_continuous_scale=px.colors.sequential.Purp)\n","\n","fig9.update_layout(plot_bgcolor='rgb(30,30,30)', paper_bgcolor='rgb(30,30,30)', font=dict(color='white'))\n","\n","fig9.show()"]},{"cell_type":"markdown","metadata":{},"source":["使用Pandas的groupby()方法，计算了根据物业形状和地势轮廓进行分组后的平均售价，分别存储在shape_prices和contour_prices中。\n","\n","创建了两个条形图fig7和fig8。x参数分别为物业形状和地势轮廓，y参数分别为对应的平均售价，title参数分别为图表的标题，template参数用于指定图表的样式模板，text参数为条形上显示的文本，这里为平均售价的值\n","\n","通过这些图表，可以直观地比较不同物业形状和地势轮廓对平均售价的影响情况。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:20.007189Z","iopub.status.busy":"2023-10-10T10:05:20.006757Z","iopub.status.idle":"2023-10-10T10:05:20.052649Z","shell.execute_reply":"2023-10-10T10:05:20.051606Z","shell.execute_reply.started":"2023-10-10T10:05:20.007172Z"},"trusted":true},"outputs":[],"source":["# 6. Calculate Correlation between Living Area and Sale Price\n","living_area_price_corr = df['GrLivArea'].corr(df['SalePrice'])\n","print(f'Correlation between Living Area (above grade) and Sale Price: {living_area_price_corr}')\n","\n","# Create a scatter plot to visualize the relationship between Living Area and Sale Price\n","fig10 = px.scatter(df, x='GrLivArea', y='SalePrice', title='Living Area (above grade) vs Sale Price', color='GrLivArea', color_continuous_scale=px.colors.sequential.Purp)\n","\n","fig10.update_layout(plot_bgcolor='rgb(30,30,30)', paper_bgcolor='rgb(30,30,30)', font=dict(color='white'))\n","\n","fig10.show()"]},{"cell_type":"markdown","metadata":{},"source":["使用corr()方法计算了生活面积和售价之间的相关系数，将结果存储在living_area_price_corr变量中。\n","\n","调用px.scatter()函数创建了一个散点图fig10。其中，x参数为生活面积，y参数为售价，title参数为图表的标题，color参数为生活面积（GrLivArea）用于给点添加颜色，color_continuous_scale参数设置颜色渐变的色谱类型（这里使用了紫色调的色谱）\n","\n","代码中的print()语句用于打印生活面积与售价之间的相关系数。\n","\n","通过散点图可以直观地观察到生活面积与售价之间的趋势和关系，相关性系数则提供了一个数值上的度量。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:20.054330Z","iopub.status.busy":"2023-10-10T10:05:20.054090Z","iopub.status.idle":"2023-10-10T10:05:20.189792Z","shell.execute_reply":"2023-10-10T10:05:20.188678Z","shell.execute_reply.started":"2023-10-10T10:05:20.054312Z"},"trusted":true},"outputs":[],"source":["# 7. Box plot of price over the years\n","yearly_avg_sale_price = df.groupby('YrSold')['SalePrice'].mean()\n","\n","fig13 = px.box(df, x='YrSold', y='SalePrice', title='Sale Price Trends Over the Years',\n","               points=False, color_discrete_sequence=['green'])\n","\n","fig13.add_trace(px.line(x=yearly_avg_sale_price.index, y=yearly_avg_sale_price.values).data[0])\n","\n","fig13.update_traces(line=dict(color='purple', width=4), selector=dict(type='scatter', mode='lines'))\n","\n","for year, avg_price in yearly_avg_sale_price.items():\n","    fig13.add_annotation(\n","        x=year,\n","        y=avg_price,\n","        text=f\"{avg_price:,.0f}\",\n","        font=dict(color='white'),\n","        showarrow=False,\n","        bgcolor='rgba(128, 0, 128, 0.6)'\n","    )\n","\n","fig13.update_layout(\n","    plot_bgcolor='rgb(30,30,30)',\n","    paper_bgcolor='rgb(30,30,30)',\n","    font=dict(color='white'),\n","    xaxis_title='Year Sold',\n","    yaxis_title='Sale Price'\n",")\n","\n","fig13.show()"]},{"cell_type":"markdown","metadata":{},"source":["使用groupby()方法按照年份（YrSold）计算了每年的平均售价，并将结果存储在yearly_avg_sale_price中。\n","\n","调用px.box()函数创建了一个箱线图fig13。其中，x参数为年份，y参数为售价，title参数为图表的标题，points参数设置为False以隐藏异常值点，color_discrete_sequence参数设置箱线的颜色为绿色\n","\n","调用px.line()函数创建了一条折线图，用来表示每年的平均售价变化趋势。通过.data[0]获取折线图的数据，并将其添加到箱线图中。\n","\n","调用update_traces()方法对折线进行设置，包括设置颜色为紫色、宽度为4。\n","\n","使用for循环遍历每个年份和平均售价，在图表中添加了注释，显示每个年份对应的平均售价，并自定义了注释的样式。\n","\n","通过这个箱线图，可以看出不同年份的售价分布情况和趋势，同时折线图则突出了平均售价的变化趋势。"]},{"cell_type":"markdown","metadata":{},"source":["中位数（Median）：箱线图中的中间线代表了数据的中位数，即将数据按升序排列后位于中间位置的值。它表示了整体数据的中心趋势。\n","\n","箱体（Box）：箱体由上下两条边界线包围，代表了数据的四分位数（quartiles）。箱体的上边界表示75%的数据落在该值之下，下边界表示25%的数据落在该值之上。箱体的高度反映了数据的离散程度。\n","\n","上限和下限（Whiskers）：箱线图上下两端的线段被称为“须”或“whiskers”。它们延伸至数据中的最大和最小非异常值，用于表示数据的范围。\n","\n","异常值（Outliers）：箱线图中的圆点或其他符号表示的数据点被认为是异常值。它们远离箱体和须线，可能代表了与其他数据点显著不同的观测结果。\n","\n","举个例子来解读箱线图：假设在某个年份的箱线图中，箱体较低位置的边界线大约在10万美元，较高位置的边界线大约在20万美元，中位数位于箱体的中间位置，即15万美元。须线的上限延伸至30万美元，下限延伸至5万美元，表示了数据的范围。此外，图中有几个圆点远离箱体和须线，可能代表了一些异常值。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:20.191321Z","iopub.status.busy":"2023-10-10T10:05:20.191033Z","iopub.status.idle":"2023-10-10T10:05:20.564572Z","shell.execute_reply":"2023-10-10T10:05:20.563353Z","shell.execute_reply.started":"2023-10-10T10:05:20.191301Z"},"trusted":true},"outputs":[],"source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","\n","#Define transformers for numerical and categorical columns\n","numerical_transformer = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='mean')),\n","    ('scaler', StandardScaler())\n","])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('imputer',SimpleImputer(strategy='constant', fill_value='missing')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore',sparse = False))\n","])"]},{"cell_type":"markdown","metadata":{},"source":["创建两个转换器（transformer）来处理数值型和分类型变量，分别命名为numerical_transformer和categorical_transformer。这两个转换器都是使用Pipeline构建的，通过steps参数指定每个步骤的名称和要执行的操作。\n","\n","numerical_transformer中的第一步是使用SimpleImputer类来填补缺失值。在这里，我们使用均值来填充缺失值，可以通过设置strategy参数为'mean'来实现。接下来，将使用StandardScaler类对所有的数值型特征进行标准化（Z-score标准化），以确保它们拥有相同的单位和范围。\n","\n","categorical_transformer与numerical_transformer类似，但其处理的是分类型特征。在这里，将使用SimpleImputer填补缺失值，但这次采用常数填补法（constant，填补值为'missing'）。由于分类型特征不能直接输入模型中，因此，还要使用OneHotEncoder将分类型特征转换为二进制的数值型特征，即进行独热编码（One-Hot Encoding）。这可以通过将handle_unknown参数设置为'ignore', sparse参数设置为False 来实现。\n","\n","使用ColumnTransformer将这两个转换器适当地应用到数据集中。可以使用remainder参数来指定如何处理没有被转换器覆盖的列。在这里，我们将其设置为'passthrough'以保留未被转换的列。\n","\n","通过这些步骤，我们可以创建一个预处理管道，用于在训练和测试数据上执行对数据集的预处理。仅需定义这些pipeline 然后在数据上fit和transform 即可完成预处理。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:20.566255Z","iopub.status.busy":"2023-10-10T10:05:20.565754Z","iopub.status.idle":"2023-10-10T10:05:20.610048Z","shell.execute_reply":"2023-10-10T10:05:20.609216Z","shell.execute_reply.started":"2023-10-10T10:05:20.566229Z"},"trusted":true},"outputs":[],"source":["#Update categorical and numerical columns\n","categorical_columns = df.select_dtypes(include=['object','category']).columns\n","numerical_columns = df.select_dtypes(include=['int64','float64']).columns\n","\n","#Remove target variable from numerical columns\n","numerical_columns = numerical_columns.drop('SalePrice')\n","\n","#Combine transformers using ColumnTransformer\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num',numerical_transformer, numerical_columns),\n","    ('cat',categorical_transformer,categorical_columns)\n","],remainder = 'passthrough')\n","\n","#Create a pipeline with the preprocessor\n","pipeline = Pipeline(steps=[\n","    ('preprocessor',preprocessor)\n","])\n","\n","#Apply the pipeline to your dataset\n","X = df.drop('SalePrice', axis=1)\n","y = np.log(df['SalePrice'])  #normalize dependent variable\n","X_preprocessed = pipeline.fit_transform(X)"]},{"cell_type":"markdown","metadata":{},"source":["使用select_dtypes函数和include参数，将列类型限制为对象（object）和类别（category）的列，将列类型限制为整数（int64）和浮点数（float64）的列。然后，将结果分配给categorical_columns和numerical_columns变量。\n","\n","从numerical_columns中移除目标变量（'SalePrice'），通过调用drop函数并将目标变量名称作为参数来实现。\n","\n","使用ColumnTransformer将两个转换器（numerical_transformer和categorical_transformer）组合起来。这里使用了两个元组，第一个元组指定了数值列的步骤名称（'num'）、数值型转换器以及要应用转换器的数值列；第二个元组指定了分类型列的步骤名称（'cat'）、分类型转换器以及要应用转换器的分类型列。设置remainder参数为'passthrough'，以便保留没有被转换器覆盖的列。\n","\n","创建一个Pipeline，其中包含preprocessor转换器。将该转换器命名为'preprocessor'。\n","\n","将Pipeline应用于数据集。首先，将数据框X中的目标变量（'SalePrice'）从X中删除，得到新的数据框X（没有目标变量）。接下来，对目标变量进行对数变换，这可以通过使用np.log函数实现，然后将结果赋值给y。最后，使用Pipeline的fit_transform方法将preprocessor应用于X，得到经过预处理的数据集X_preprocessed。\n","\n","通过这些步骤，你可以使用Pipeline对原始数据集进行预处理，获得经过转换和缺失值填补的特征矩阵X_preprocessed，以及经过对数变换的目标变量y。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:05:20.611370Z","iopub.status.busy":"2023-10-10T10:05:20.611037Z","iopub.status.idle":"2023-10-10T10:07:47.744082Z","shell.execute_reply":"2023-10-10T10:07:47.743345Z","shell.execute_reply.started":"2023-10-10T10:05:20.611351Z"},"trusted":true},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n","\n","#Split the data into training and test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n","\n","#Define the models\n","models={\n","    'LinearRegression':LinearRegression(),\n","    'RandomForest':RandomForestRegressor(random_state=42),\n","    'XGBoost':XGBRegressor(random_state=42)\n","}\n","\n","#Define the hyperparameter grids for each model\n","param_grids={\n","    'LinearRegression':{},\n","    'RandomForest':{\n","        'n_estimators':[100,200,500],\n","        'max_depth':[None,10,30],\n","        'min_samples_split':[2,5,10],\n","    },\n","    'XGBoost':{\n","        'n_estimators':[100,200,500],\n","        'learning_rate':[0.01,0.1,0.3],\n","        'max_depth':[3,6,10],\n","    }\n","}\n","\n","#3-fold cross_validation\n","cv = KFold(n_splits=3, shuffle=True, random_state=42)\n","\n","#Train and tune the models\n","grids = {}\n","for model_name, model in models.items():\n","    #print(f'Training and tuning {model_name}...')\n","    grids[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=cv, \n","                                     scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n","    grids[model_name].fit(X_train, y_train)\n","    best_params = grids[model_name].best_params_\n","    best_score = np.sqrt(-1 * grids[model_name].best_score_)\n","    \n","    print(f'Best parameters for {model_name}:{best_params}')\n","    print(f'Best RMSE for {model_name}:{best_score}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["首先，将数据集划分为训练集和测试集，比例为80%的训练集和20%的测试集。\n","\n","定义了一个字典models，包含了三个模型：线性回归（LinearRegression）、随机森林（RandomForestRegressor）和XGBoost（XGBRegressor）\n","\n","定义了一个字典param_grids，包含了每个模型的超参数网格。对于线性回归，没有定义任何超参数；对于随机森林，定义了n_estimators、max_depth和min_samples_split；对于XGBoost，定义了n_estimators、learning_rate和max_depth。\n","\n","创建了一个KFold对象，将数据集划分为3折交叉验证集。\n","\n","对于每个模型，创建了一个GridSearchCV对象，将模型、超参数网格、交叉验证对象等作为参数传入。设置了scoring参数为'neg_mean_squared_error'，使用均方根误差（RMSE）作为评分指标。设置了n_jobs参数为-1，以便使用所有可用的CPU进行并行计算。设置了verbose参数为2，以便输出详细的训练信息。\n","\n","调用GridSearchCV对象的fit方法，在训练集上进行网格搜索和交叉验证。通过调用best_params_属性和best_score_属性，获取最佳超参数和最佳RMSE值。\n","\n","打印出每个模型的最佳超参数和最佳RMSE值。（RMSE值越小代表模型拟合效果越好，模型的预测结果也越准确）\n","\n","整段代码的意义在于通过自动化的方式探索不同模型及其超参数组合的性能，以帮助选择最佳的模型和超参数配置。通过对不同模型的比较评估，可以找到在训练数据上表现最好的模型，并使用其最佳超参数配置进行后续预测任务。这有助于提高预测精度并优化模型性能。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:07:47.745259Z","iopub.status.busy":"2023-10-10T10:07:47.744993Z","iopub.status.idle":"2023-10-10T10:08:46.376191Z","shell.execute_reply":"2023-10-10T10:08:46.375394Z","shell.execute_reply.started":"2023-10-10T10:07:47.745229Z"},"trusted":true},"outputs":[],"source":["\n","from sklearn.neural_network import MLPRegressor\n","\n","X_train_scaled = X_train.copy()\n","X_test_scaled = X_test.copy()\n","\n","# Create an MLPRegressor instance\n","mlp = MLPRegressor(random_state=42,max_iter=10000, n_iter_no_change = 3,learning_rate_init=0.001)\n","\n","# Define the parameter grid for tuning\n","param_grid = {\n","    'hidden_layer_sizes': [(10,), (10,10), (10,10,10), (25)],\n","    'activation': ['relu', 'tanh'],\n","    'solver': ['adam'],\n","    'alpha': [0.0001, 0.001, 0.01],\n","    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n","}\n","\n","# Create the GridSearchCV object\n","grid_search_mlp = GridSearchCV(mlp, param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n","\n","# Fit the model on the training data\n","grid_search_mlp.fit(X_train_scaled, y_train)\n","\n","# Print the best parameters found during the search\n","print(\"Best parameters found: \", grid_search_mlp.best_params_)\n","\n","# Evaluate the model on the test data\n","best_score = np.sqrt(-1 * grid_search_mlp.best_score_)\n","print(\"Test score: \", best_score)"]},{"cell_type":"markdown","metadata":{},"source":["导入MLPRegressor类，它是多层感知机（MLP）回归模型的实现类。\n","\n","这两行代码将训练集和测试集的数据进行复制，分别存储在X_train_scaled和X_test_scaled变量中。这是为了后续对数据进行标准化处理时不改变原始数据。\n","\n","设置一个MLPRegressor模型实例mlp，其中的参数有：\n","random_state：随机种子，用于保证模型的可重复性。\n","max_iter：最大迭代次数，控制模型的训练轮数。\n","n_iter_no_change：当连续n次迭代后模型性能没有显著提高时，停止迭代。\n","learning_rate_init：学习率的初始值，用于控制模型参数的更新速度。\n","\n","定义了一个超参数网格param_grid，包含了多个超参数及其候选值。这些超参数包括：\n","hidden_layer_sizes：隐藏层的神经元数量和层数的组合。\n","activation：激活函数的选择，可以是ReLU或tanh。\n","solver：求解器的选择，这里选择了Adam优化器。\n","alpha：正则化系数的候选值。\n","learning_rate：学习率的调整方式，包括常数、递减和自适应。\n","\n","创建了一个GridSearchCV类的实例对象grid_search_mlp，用于进行超参数搜索和模型评估。其中的参数有：\n","mlp：被搜索的模型对象。\n","param_grid：超参数网格。\n","scoring：评估指标，这里采用负均方误差（neg_mean_squared_error）作为损失函数。\n","cv：交叉验证的折数。\n","n_jobs：并行任务的数量，设置为-1表示使用所有可用的CPU核心。\n","verbose：详细输出。\n","\n","在训练集上训练模型。GridSearchCV将尝试所有可能的组合，并根据指定的评分标准计算每个超参数组合下的平均性能。\n","\n","打印最佳超参数组合\n","\n","多层感知机（MLP）是一种经典的神经网络模型，由输入层、若干个隐含层和输出层构成。每个神经元接收来自上一层的输入，并通过激活函数对输入进行加权求和，最终得到输出。在回归任务中，MLPRegressor类可以通过权衡多个隐藏层、每层的神经元数量、激活函数、求解器类型、正则化系数和学习率等超参数，来优化模型的性能表现。GridSearchCV类则可以用来自动搜索最佳超参数组合与评估不同超参数下模型的性能表现。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:08:46.377827Z","iopub.status.busy":"2023-10-10T10:08:46.377393Z","iopub.status.idle":"2023-10-10T10:08:46.618015Z","shell.execute_reply":"2023-10-10T10:08:46.617259Z","shell.execute_reply.started":"2023-10-10T10:08:46.377802Z"},"trusted":true},"outputs":[],"source":["#pca\n","from sklearn.decomposition import PCA\n","\n","pca = PCA()\n","X_pca_pre = pca.fit_transform(X_preprocessed)\n","\n","#Caculate the cmulative explained variance\n","cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n","\n","#Choose the number of components based on the explained variance threshold\n","n_components = np.argmax(cumulative_explained_variance >= 0.95) + 1\n","\n","pca = PCA(n_components=n_components)\n","pipeline_pca = Pipeline(steps=\n","                       [('preprocessoe', preprocessor),\n","                       ('pca',pca)])\n","X_pca = pipeline_pca.fit_transform(X)"]},{"cell_type":"markdown","metadata":{},"source":["这行代码导入了sklearn库中的PCA类，用于进行主成分分析。\n","\n","创建了一个PCA类的实例对象pca，并调用fit_transform()方法对经过预处理后的数据X_preprocessed进行主成分分析。该方法将返回降维后的数据X_pca_pre。\n","\n","计算了累计解释方差。explained_variance_ratio_属性表示每个主成分解释的方差比例，通过np.cumsum()函数对其进行累计求和，得到每个主成分解释方差的累积值。\n","\n","选择降维后保留的主成分数量。根据累计解释方差大于等于0.95的条件，使用np.argmax()函数找到第一个满足条件的索引，并加1得到主成分的数量。我们希望选择尽可能少的主成分来达到降维的目标，同时保留足够的数据信息。一种常用的选择方法是设定一个阈值，比如0.95，表示希望保留至少95%的原始数据方差。\n","\n","重新创建一个PCA实例对象pca，将降维后保留的主成分数量作为参数传入。然后，构建了一个Pipeline对象pipeline_pca，其中包含预处理器和PCA模型，按照先预处理后进行PCA的顺序组成。最后，调用fit_transform()方法对原始数据X进行预处理和主成分分析，得到降维后的数据X_pca。\n","\n","通过以上代码，你可以实现对数据进行PCA降维处理，并选择保留多少个主成分来达到一定的解释方差阈值。降维后的数据可以在X_pca中使用。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:08:46.620753Z","iopub.status.busy":"2023-10-10T10:08:46.619624Z","iopub.status.idle":"2023-10-10T10:12:35.290859Z","shell.execute_reply":"2023-10-10T10:12:35.290227Z","shell.execute_reply.started":"2023-10-10T10:08:46.620728Z"},"trusted":true},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n","\n","# Split the data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n","\n","# Define the models\n","models = {\n","    'LinearRegression': LinearRegression(),\n","    'RandomForest': RandomForestRegressor(random_state=42),\n","    'XGBoost': XGBRegressor(random_state=42)\n","}\n","\n","# Define the hyperparameter grids for each model\n","param_grids = {\n","    'LinearRegression': {},\n","    'RandomForest': {\n","        'n_estimators': [100, 200, 500],\n","        'max_depth': [None, 10, 30],\n","        'min_samples_split': [2, 5, 10],\n","    },\n","    'XGBoost': {\n","        'n_estimators': [100, 200, 500],\n","        'learning_rate': [0.01, 0.1, 0.3],\n","        'max_depth': [3, 6, 10],\n","    }\n","}\n","\n","# 3-fold cross-validation\n","cv = KFold(n_splits=3, shuffle=True, random_state=42)\n","\n","# Train and tune the models\n","grids_pca = {}\n","for model_name, model in models.items():\n","    #print(f'Training and tuning {model_name}...')\n","    grids_pca[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n","    grids_pca[model_name].fit(X_train_pca, y_train_pca)\n","    best_params = grids_pca[model_name].best_params_\n","    best_score = np.sqrt(-1 * grids_pca[model_name].best_score_)\n","    \n","    print(f'Best parameters for {model_name}: {best_params}')\n","    print(f'Best RMSE for {model_name}: {best_score}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["代码通过指定数据集的训练集和测试集的划分比例，使用train_test_split函数将数据集X_pca和y划分为训练集和测试集。划分比例为0.2，即80%的数据作为训练集，20%的数据作为测试集。\n","\n","自变量是pca处理过的x，因变量还是y"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:12:35.292541Z","iopub.status.busy":"2023-10-10T10:12:35.292314Z","iopub.status.idle":"2023-10-10T10:16:01.204395Z","shell.execute_reply":"2023-10-10T10:16:01.203232Z","shell.execute_reply.started":"2023-10-10T10:12:35.292523Z"},"trusted":true},"outputs":[],"source":["from sklearn.neural_network import MLPRegressor\n","\n","X_train_scaled_pca = X_train_pca.copy()\n","X_test_scaled_pca = X_test_pca.copy()\n","\n","#Create an MLPRegressor instance\n","mlp = MLPRegressor(random_state=42, max_iter=10000, n_iter_no_change = 3,learning_rate_init=0.001)\n","\n","#Define the parameter grid for tuning\n","param_grid = {\n","    'hidden_layer_sizes':[(10,),(10,10),(10,10,10),(25)],\n","    'activation':['relu','tanh'],\n","    'solver':['adam'],\n","    'alpha':[0.0001, 0.001, 0.01, .1, 1],\n","    'learning_rate':['constant','invscaling','adaptive'],\n","}\n","\n","#Create the GridSearchCV object\n","grid_search_mlp_pca = GridSearchCV(mlp, param_grid, scoring='neg_mean_squared_error',cv=3,n_jobs=-1,verbose=1)\n","\n","\n","#Fit the model on the training data\n","grid_search_mlp_pca.fit(X_train_scaled_pca, y_train)\n","\n","#Print the best parameters found during the search\n","print('Best parameters found:', grid_search_mlp_pca.best_params_)\n","\n","#Evaluate the model on the test data\n","best_score = np.sqrt(-1*grid_search_mlp_pca.best_score_)\n","print('Test score:',best_score)"]},{"cell_type":"markdown","metadata":{},"source":["\n","自变量是pca处理过的x，因变量还是y，其他一致"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.205742Z","iopub.status.busy":"2023-10-10T10:16:01.205488Z","iopub.status.idle":"2023-10-10T10:16:01.275471Z","shell.execute_reply":"2023-10-10T10:16:01.274831Z","shell.execute_reply.started":"2023-10-10T10:16:01.205716Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","for i in grids.keys():\n","    print(i + ':' + str(np.sqrt(mean_squared_error(grids[i].predict(X_test),y_test))))\n"]},{"cell_type":"markdown","metadata":{},"source":["通过for循环遍历grids字典中存储的每个模型的网格搜索对象\n","\n","i 是循环变量，代表当前迭代中所遍历的模型名称。\n","\n","grids[i].predict(X_test) 使用网格搜索得到的最佳模型对测试集数据 X_test 进行预测，得到预测值。\n","\n","mean_squared_error(grids[i].predict(X_test), y_test) 使用真实的目标值 y_test 和模型预测的目标值之间的平均偏差大小来计算均方根误差（RMSE）。\n","\n","\n","np.sqrt(mean_squared_error(grids[i].predict(X_test), y_test)) 使用 numpy 库中的 sqrt 函数对均方根误差进行开方，以得到更直观的误差值。\n","\n","str(np.sqrt(mean_squared_error(grids[i].predict(X_test), y_test))) 将得到的均方根误差转换为字符串形式。\n","\n","i + ':' + str(np.sqrt(mean_squared_error(grids[i].predict(X_test), y_test))) 将模型名称和对应的均方根误差拼接成一个字符串，并打印输出。\n","\n","这段代码的作用是使用测试集数据来评估训练好的模型在新数据上的表现，以了解模型的泛化能力。对于每个模型，使用均方根误差（RMSE）来量化预测误差，并将其打印输出以进行模型比较。\n","\n","测试对象是每个模型的X_test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.282844Z","iopub.status.busy":"2023-10-10T10:16:01.282400Z","iopub.status.idle":"2023-10-10T10:16:01.338616Z","shell.execute_reply":"2023-10-10T10:16:01.337910Z","shell.execute_reply.started":"2023-10-10T10:16:01.282819Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","for i in grids.keys():\n","    print (i + ': ' + str(np.sqrt(mean_squared_error(grids_pca[i].predict(X_test_pca), y_test))))"]},{"cell_type":"markdown","metadata":{},"source":["测试对象是3个模型的X_test_pca，其余一样\n","\n","输出3个模型pca处理过的RMSE值"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.340277Z","iopub.status.busy":"2023-10-10T10:16:01.339796Z","iopub.status.idle":"2023-10-10T10:16:01.346323Z","shell.execute_reply":"2023-10-10T10:16:01.345636Z","shell.execute_reply.started":"2023-10-10T10:16:01.340251Z"},"trusted":true},"outputs":[],"source":["print( str(np.sqrt(mean_squared_error(grid_search_mlp.predict(X_test_scaled),y_test))))"]},{"cell_type":"markdown","metadata":{},"source":["使用了另外一个模型 grid_search_mlp，对测试数据集 X_test_scaled 进行预测，并计算预测值和真实值之间的均方根误差（RMSE）。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.348051Z","iopub.status.busy":"2023-10-10T10:16:01.347546Z","iopub.status.idle":"2023-10-10T10:16:01.357291Z","shell.execute_reply":"2023-10-10T10:16:01.356603Z","shell.execute_reply.started":"2023-10-10T10:16:01.348027Z"},"trusted":true},"outputs":[],"source":["print( str(np.sqrt(mean_squared_error(grid_search_mlp_pca.predict(X_test_scaled_pca), y_test))))\n"]},{"cell_type":"markdown","metadata":{},"source":["使用了经过 PCA（主成分分析）处理后的测试集数据 X_test_scaled_pca。\n","\n","使用了另一个模型 grid_search_mlp_pca，该模型是在 PCA 处理后的数据上训练的。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.359038Z","iopub.status.busy":"2023-10-10T10:16:01.358538Z","iopub.status.idle":"2023-10-10T10:16:01.713567Z","shell.execute_reply":"2023-10-10T10:16:01.712909Z","shell.execute_reply.started":"2023-10-10T10:16:01.359013Z"},"trusted":true},"outputs":[],"source":["var_explore = df[['Fence','Alley','MiscFeature','PoolQC','FireplaceQu','GarageCond','GarageQual','GarageFinish','GarageType','BsmtExposure','BsmtFinType2','BsmtFinType1','BsmtCond','BsmtQual','MasVnrType','Electrical','MSZoning','Utilities','Exterior1st','Exterior2nd','KitchenQual','Functional','SaleType','LotFrontage','GarageYrBlt','MasVnrArea','BsmtFullBath','BsmtHalfBath','GarageCars','GarageArea','TotalBsmtSF']]\n","\n","display(HTML(create_scrollable_table(var_explore, 'var_explore', 'List of Variables to Explore for Feature Engineering')))"]},{"cell_type":"markdown","metadata":{},"source":["df[['Fence','Alley','MiscFeature',...,'GarageArea','TotalBsmtSF']] 使用双方括号，选择了 DataFrame 数据中的多个列，这些列名分别为 'Fence', 'Alley', 'MiscFeature', ... , 'GarageArea', 'TotalBsmtSF'。\n","\n","display(HTML(create_scrollable_table(var_explore, 'var_explore', 'List of Variables to Explore for Feature Engineering'))) 该行代码将选择的数据表格使用 create_scrollable_table 函数转换为 HTML 表格，并通过 display(HTML(...)) 函数显示在网页上。其中，'var_explore' 是 HTML 表格的 id，用于后续的 CSS 样式调整。'List of Variables to Explore for Feature Engineering' 是表格的标题。\n","\n","最终的输出结果是一个包含了所选特征变量的可滚动 HTML 表格，方便展示和探索这些变量的数据分布和统计信息。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.715069Z","iopub.status.busy":"2023-10-10T10:16:01.714624Z","iopub.status.idle":"2023-10-10T10:16:01.722434Z","shell.execute_reply":"2023-10-10T10:16:01.721560Z","shell.execute_reply.started":"2023-10-10T10:16:01.715048Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import FunctionTransformer\n","\n","# feature engineering functions \n","def custom_features(df):\n","    df_out = df.copy()\n","    df_out['PropertyAge'] = df_out['YrSold'] - df_out['YearBuilt']\n","    df_out['TotalSF'] = df_out['TotalBsmtSF'] + df_out['1stFlrSF'] + df_out['2ndFlrSF']\n","    df_out['TotalBath'] = df_out['FullBath'] + 0.5 * df_out['HalfBath'] + df_out['BsmtFullBath'] + 0.5 * df['BsmtHalfBath']\n","    df_out['HasRemodeled'] = (df_out['YearRemodAdd'] != df_out['YearBuilt']).astype(object)\n","    df_out['Has2ndFloor'] = (df_out['2ndFlrSF'] > 0).astype(object)\n","    df_out['HasGarage'] = (df_out['GarageArea'] > 0).astype(object)\n","    df_out['YrSold_cat'] = df_out['YrSold'].astype(object)\n","    df_out['MoSold_cat'] = df_out['MoSold'].astype(object)\n","    df_out['YearBuilt_cat'] = df_out['YearBuilt'].astype(object)\n","    df_out['MSSubClass_cat'] = df_out['MSSubClass'].astype(object)\n","    \n","    return df_out\n","\n","feature_engineering_transformer = FunctionTransformer(custom_features)\n","\n","\n","#make this better, one functtion? get new variables in the pipeline? "]},{"cell_type":"markdown","metadata":{},"source":["custom_features(df) 是一个自定义的特征工程函数，接受一个 DataFrame df 作为输入，并对其进行一系列操作和变换，生成新的特征，并返回处理后的 DataFrame df_out。\n","\n","计算房屋的 PropertyAge 特征，即当前年份 'YrSold' 减去建房年份 'YearBuilt'。\n","\n","计算总面积特征 TotalSF，即地下室面积 'TotalBsmtSF' 加上一楼面积 '1stFlrSF' 和二楼面积 '2ndFlrSF' 的和。\n","\n","计算总浴室数量特征 TotalBath，其中包括全浴室数量 'FullBath'、半浴室数量 'HalfBath'（乘以 0.5 来表示），地下室全浴室数量 'BsmtFullBath' 和地下室半浴室数量 'BsmtHalfBath'（乘以 0.5）的总和。\n","\n","创建布尔特征 HasRemodeled，判断是否进行过房屋翻新，即 'YearRemodAdd' 是否与 'YearBuilt' 不相等，并将其转换为对象类型（object）。\n","\n","创建布尔特征 Has2ndFloor，判断是否有二楼，即二楼面积 '2ndFlrSF' 是否大于 0，并将其转换为对象类型（object）。\n","\n","创建布尔特征 HasGarage，判断是否有车库，即车库面积 'GarageArea' 是否大于 0，并将其转换为对象类型（object）。\n","\n","将年份特征 'YrSold'、'MoSold'、'YearBuilt' 和 'MSSubClass' 转换为对象类型（object），以便后续处理。\n","\n","feature_engineering_transformer = FunctionTransformer(custom_features) 使用 FunctionTransformer 将自定义的特征工程函数 custom_features 转换为可用于机器学习流水线的转换器 feature_engineering_transformer。\n","\n","最后一条注释中提到了对代码进行进一步优化的可能性，具体优化方式需要根据实际情况和需求进一步考虑，比如将生成新特征的步骤整合到机器学习流水线中，以提高代码的整体性能和可读性。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:01.723910Z","iopub.status.busy":"2023-10-10T10:16:01.723640Z","iopub.status.idle":"2023-10-10T10:16:01.886389Z","shell.execute_reply":"2023-10-10T10:16:01.885738Z","shell.execute_reply.started":"2023-10-10T10:16:01.723863Z"},"trusted":true},"outputs":[],"source":["# Identify categorical and numerical columns\n","new_cols_categorical = pd.Index(['HasRemodeled', 'Has2ndFloor', 'HasGarage'])\n","new_cols_numeric = pd.Index(['PropertyAge', 'TotalSF', 'TotalBath', 'YrSold_cat', 'MoSold_cat', 'YearBuilt_cat', 'MSSubClass_cat'])\n","\n","# Update categorical and numerical columns\n","categorical_columns = df.select_dtypes(include=['object', 'category']).columns.append(new_cols_categorical)\n","numerical_columns = df.select_dtypes(include=['int64', 'float64']).columns.append(new_cols_numeric)\n","\n","# Remove target variable from numerical columns\n","numerical_columns = numerical_columns.drop('SalePrice')\n","\n","# Combine transformers using ColumnTransformer\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numerical_transformer, numerical_columns),\n","        ('cat', categorical_transformer, categorical_columns)\n","    ],remainder = 'passthrough')\n","\n","# Create a pipeline with the preprocessor\n","pipeline_fe = Pipeline(steps=[\n","    ('fe', feature_engineering_transformer),\n","    ('preprocessor', preprocessor),\n","    ('pca', pca)])\n","\n","# Apply the pipeline to your dataset\n","X = df.drop('SalePrice', axis=1)\n","y = np.log(df['SalePrice'])\n","X_preprocessed_fe = pipeline_fe.fit_transform(X)"]},{"cell_type":"markdown","metadata":{},"source":["new_cols_categorical 是一个包含新分类列的索引，这些列是在特征工程中生成的。\n","\n","new_cols_numeric 是一个包含新数值列的索引，这些列也是在特征工程中生成的。\n","\n","categorical_columns 是包含所有分类列的索引，其中包括原始数据集中的分类列和新生成的分类列。\n","\n","numerical_columns 是包含所有数值列的索引，其中包括原始数据集中的数值列和新生成的数值列。\n","\n","将目标变量从数值列中删除，得到更新后的数值列索引 numerical_columns。\n","\n","使用 ColumnTransformer 将转换器组合在一起。preprocessor 包含两个转换器：'num' 转换器使用 numerical_transformer 对数值列进行转换，'cat' 转换器使用 categorical_transformer 对分类列进行转换。同时，设\n","置 remainder='passthrough'，以保留未被转换的其他列。\n","\n","创建一个包含特征工程的流水线 pipeline_fe，它包括三个步骤：特征工程转换器 feature_engineering_transformer、预处理器 preprocessor 和 PCA（主成分分析）。\n","\n","将流水线应用于数据集。首先从数据集中去除目标变量 SalePrice，然后对样本使用流水线进行特征提取和预处理，得到转换后的数据集 X_preprocessed_fe。同时，将目标变量 SalePrice 取对数，存储在变量 y 中。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:16:33.348113Z","iopub.status.busy":"2023-10-10T10:16:33.347796Z","iopub.status.idle":"2023-10-10T10:20:28.976537Z","shell.execute_reply":"2023-10-10T10:20:28.975787Z","shell.execute_reply.started":"2023-10-10T10:16:33.348094Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and testing sets\n","from sklearn.model_selection import train_test_split\n","X_train_fe, X_test_fe, y_train_fe, y_test_fe = train_test_split(X_preprocessed_fe, y, test_size=0.2, random_state=42)\n","\n","# Define the models\n","models = {\n","    'LinearRegression': LinearRegression(),\n","    'RandomForest': RandomForestRegressor(random_state=42),\n","    'XGBoost': XGBRegressor(random_state=42)\n","}\n","\n","# Define the hyperparameter grids for each model\n","param_grids = {\n","    'LinearRegression': {},\n","    'RandomForest': {\n","        'n_estimators': [100, 200, 500],\n","        'max_depth': [None, 10, 30],\n","        'min_samples_split': [2, 5, 10],\n","    },\n","    'XGBoost': {\n","        'n_estimators': [100, 200, 500],\n","        'learning_rate': [0.01, 0.1, 0.3],\n","        'max_depth': [3, 6, 10],\n","    }\n","}\n","\n","# 3-fold cross-validation\n","cv = KFold(n_splits=3, shuffle=True, random_state=42)\n","\n","# Train and tune the models\n","grids_fe = {}\n","for model_name, model in models.items():\n","    #print(f'Training and tuning {model_name}...')\n","    grids_fe[model_name] = GridSearchCV(estimator=model, param_grid=param_grids[model_name], cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n","    grids_fe[model_name].fit(X_train_fe, y_train_fe)\n","    best_params = grids_fe[model_name].best_params_\n","    best_score = np.sqrt(-1 * grids_fe[model_name].best_score_)\n","    \n","    print(f'Best parameters for {model_name}: {best_params}')\n","    print(f'Best RMSE for {model_name}: {best_score}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["与之前的3个模型代码一致，只是变量变成了fe和pca过的数据X_fe"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:26:23.024060Z","iopub.status.busy":"2023-10-10T10:26:23.023725Z","iopub.status.idle":"2023-10-10T10:31:05.175506Z","shell.execute_reply":"2023-10-10T10:31:05.174469Z","shell.execute_reply.started":"2023-10-10T10:26:23.024031Z"},"trusted":true},"outputs":[],"source":["X_train_scaled_fe = X_train_fe.copy()\n","X_test_scaled_fe = X_test_fe.copy()\n","\n","# Create an MLPRegressor instance\n","from sklearn.neural_network import MLPRegressor\n","\n","mlp = MLPRegressor(random_state=42, max_iter=10000, n_iter_no_change=3)\n","\n","# Define the parameter grid for tuning\n","param_grid = {\n","    'hidden_layer_sizes': [(10,), (10, 10), (10, 25)],\n","    'activation': ['relu', 'tanh', 'sigmoid'],\n","    'solver': ['adam', 'sgd'],\n","    'alpha': [.1, .5, 1, 10, 100],\n","    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n","    'learning_rate_init' : [0.1]\n","}\n","\n","# Create the GridSearchCV object\n","from sklearn.model_selection import GridSearchCV\n","grid_search_mlp_fe = GridSearchCV(mlp, param_grid, scoring='neg_mean_squared_error', cv=3, n_jobs=-1, verbose=1)\n","\n","# Fit the model on the training data\n","grid_search_mlp_fe.fit(X_train_scaled_fe, y_train_fe)\n","\n","# Print the best parameters found during the search\n","print(\"Best parameters found: \", grid_search_mlp_fe.best_params_)\n","\n","# Evaluate the model on the test data\n","best_score = np.sqrt(-1 * grid_search_mlp_fe.best_score_)\n","print(\"Test score: \", best_score)"]},{"cell_type":"markdown","metadata":{},"source":["与之前的MLP一致，只是数据变成了fe和pca过的X_fe"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:21:57.421162Z","iopub.status.busy":"2023-10-10T10:21:57.419720Z","iopub.status.idle":"2023-10-10T10:21:57.513567Z","shell.execute_reply":"2023-10-10T10:21:57.512521Z","shell.execute_reply.started":"2023-10-10T10:21:57.421114Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import mean_squared_error\n","for i in grids.keys():\n","    print (i + ': ' + str(np.sqrt(mean_squared_error(grids_fe[i].predict(X_test_fe), y_test))))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:31:17.651283Z","iopub.status.busy":"2023-10-10T10:31:17.650946Z","iopub.status.idle":"2023-10-10T10:31:17.657722Z","shell.execute_reply":"2023-10-10T10:31:17.656936Z","shell.execute_reply.started":"2023-10-10T10:31:17.651259Z"},"trusted":true},"outputs":[],"source":["print( str(np.sqrt(mean_squared_error(grid_search_mlp_fe.predict(X_test_scaled_fe),y_test))))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:33:42.938600Z","iopub.status.busy":"2023-10-10T10:33:42.938307Z","iopub.status.idle":"2023-10-10T10:33:43.008026Z","shell.execute_reply":"2023-10-10T10:33:43.007277Z","shell.execute_reply.started":"2023-10-10T10:33:42.938581Z"},"trusted":true},"outputs":[],"source":["df_test = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv')\n","df_test_preprocessed = pipeline_fe.transform(df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:38:35.457930Z","iopub.status.busy":"2023-10-10T10:38:35.457582Z","iopub.status.idle":"2023-10-10T10:38:35.476135Z","shell.execute_reply":"2023-10-10T10:38:35.475047Z","shell.execute_reply.started":"2023-10-10T10:38:35.457897Z"},"trusted":true},"outputs":[],"source":["#xgboost submission\n","y_xgboost = np.exp(grids_fe['XGBoost'].predict(df_test_preprocessed))\n","\n","df_xgboost_out = df_test[['Id']].copy()\n","df_xgboost_out['SalePrice'] = y_xgboost\n","\n","#\n","df_xgboost_out.to_csv('submission_xgboost_new_features_normalized.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["将id和XGBoost预测值组成一个两列的表格，输出为csv文件（选择的是fe和pca过的数据训练出来的那次模型）"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:38:49.155304Z","iopub.status.busy":"2023-10-10T10:38:49.154969Z","iopub.status.idle":"2023-10-10T10:38:49.165841Z","shell.execute_reply":"2023-10-10T10:38:49.164572Z","shell.execute_reply.started":"2023-10-10T10:38:49.155281Z"},"trusted":true},"outputs":[],"source":["df_xgboost_out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:39:47.949501Z","iopub.status.busy":"2023-10-10T10:39:47.949195Z","iopub.status.idle":"2023-10-10T10:39:48.035104Z","shell.execute_reply":"2023-10-10T10:39:48.034194Z","shell.execute_reply.started":"2023-10-10T10:39:47.949481Z"},"trusted":true},"outputs":[],"source":["#rf submission\n","y_rf = np.exp(grids_fe['RandomForest'].predict(df_test_preprocessed))\n","\n","df_rf_out = df_test[['Id']].copy()\n","df_rf_out['SalePrice'] = y_rf\n","\n","#\n","df_rf_out.to_csv('submission_rf_normalized.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["将id和RandomForest预测值组成一个两列的表格，输出为csv文件（选择的是fe和pca过的数据训练出来的那次模型）"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:40:00.713728Z","iopub.status.busy":"2023-10-10T10:40:00.713406Z","iopub.status.idle":"2023-10-10T10:40:00.726948Z","shell.execute_reply":"2023-10-10T10:40:00.725477Z","shell.execute_reply.started":"2023-10-10T10:40:00.713708Z"},"trusted":true},"outputs":[],"source":["df_rf_out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:40:35.257330Z","iopub.status.busy":"2023-10-10T10:40:35.257037Z","iopub.status.idle":"2023-10-10T10:40:35.271124Z","shell.execute_reply":"2023-10-10T10:40:35.269930Z","shell.execute_reply.started":"2023-10-10T10:40:35.257310Z"},"trusted":true},"outputs":[],"source":["#mlp submission\n","y_mlp = np.exp(grid_search_mlp_fe.predict(df_test_preprocessed))\n","\n","df_mlp_out = df_test[['Id']].copy()\n","df_mlp_out['SalePrice'] = y_mlp\n","\n","df_mlp_out.to_csv('submission_mlp_normalized.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["将id和MLP预测值组成一个两列的表格，输出为csv文件（选择的是fe和pca过的数据训练出来的那次模型）"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:40:45.668334Z","iopub.status.busy":"2023-10-10T10:40:45.668008Z","iopub.status.idle":"2023-10-10T10:40:45.679990Z","shell.execute_reply":"2023-10-10T10:40:45.679264Z","shell.execute_reply.started":"2023-10-10T10:40:45.668313Z"},"trusted":true},"outputs":[],"source":["df_mlp_out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:42:49.673266Z","iopub.status.busy":"2023-10-10T10:42:49.672942Z","iopub.status.idle":"2023-10-10T10:42:49.686036Z","shell.execute_reply":"2023-10-10T10:42:49.684133Z","shell.execute_reply.started":"2023-10-10T10:42:49.673246Z"},"trusted":true},"outputs":[],"source":["y_avg_ens = (y_rf + y_xgboost + y_mlp)/3\n","\n","#xgboost submission\n","df_avg_ens_out = df_test[['Id']].copy()\n","df_avg_ens_out['SalePrice'] = y_avg_ens\n","\n","#\n","df_avg_ens_out.to_csv('submission_avg_ens_new_features_normalized.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["将id和RF XGB MLP三个模型预测值的平均数组成一个两列的表格，输出为csv文件（选择的是fe和pca过的数据训练出来的那次模型）"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:43:07.598489Z","iopub.status.busy":"2023-10-10T10:43:07.598189Z","iopub.status.idle":"2023-10-10T10:43:07.611912Z","shell.execute_reply":"2023-10-10T10:43:07.610510Z","shell.execute_reply.started":"2023-10-10T10:43:07.598470Z"},"trusted":true},"outputs":[],"source":["df_avg_ens_out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T10:44:48.049096Z","iopub.status.busy":"2023-10-10T10:44:48.047833Z","iopub.status.idle":"2023-10-10T12:08:36.469675Z","shell.execute_reply":"2023-10-10T12:08:36.468917Z","shell.execute_reply.started":"2023-10-10T10:44:48.049055Z"},"trusted":true},"outputs":[],"source":["from sklearn.ensemble import StackingRegressor\n","\n","grids_fe['MLP'] =   grid_search_mlp_fe\n","\n","best_estimators = [(model_name, grid.best_estimator_) for model_name, grid in grids_fe.items()]\n","\n","# Define the candidate meta-models\n","meta_models = {\n","    'MLP': MLPRegressor(random_state=42, max_iter=10000, n_iter_no_change=3, learning_rate_init=0.001),\n","    'LinearRegression': LinearRegression(),\n","    'XGBoost': XGBRegressor(random_state=42)\n","}\n","\n","# Define the hyperparameter grids for each meta-model\n","meta_param_grids = {\n","    'MLP': {\n","        'final_estimator__hidden_layer_sizes': [(10,), (10, 10)],\n","        'final_estimator__activation': ['relu', 'tanh'],\n","        'final_estimator__solver': ['adam', 'sgd'],\n","        'final_estimator__alpha': [ 0.001, 0.01, .1, .5],\n","        'final_estimator__learning_rate': ['constant', 'invscaling', 'adaptive'],\n","    },\n","    'LinearRegression': {},\n","    'XGBoost': {\n","        'final_estimator__n_estimators': [100, 200, 500],\n","        'final_estimator__learning_rate': [0.01, 0.1, 0.3],\n","        'final_estimator__max_depth': [3, 6, 10],\n","    }\n","}\n","\n","# 3-fold cross-validation\n","cv = KFold(n_splits=3, shuffle=True, random_state=42)\n","\n","# Train and tune the stacking ensemble\n","best_score = float('inf')\n","best_model = None\n","\n","for meta_name, meta_model in meta_models.items():\n","    print(f'Training and tuning {meta_name} as the meta-model...')\n","    stacking_regressor = StackingRegressor(estimators=best_estimators, final_estimator=meta_model, cv=cv)\n","    grid_search = GridSearchCV(estimator=stacking_regressor, param_grid=meta_param_grids[meta_name], cv=cv, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n","    grid_search.fit(X_train_fe, y_train_fe)\n","    best_params = grid_search.best_params_\n","    best_rmse = np.sqrt(-1 * grid_search.best_score_)\n","    \n","    print(f'Best parameters for {meta_name}: {best_params}')\n","    print(f'Best RMSE for {meta_name}: {best_rmse}\\n')\n","    \n","    if best_rmse < best_score:\n","        best_score = best_rmse\n","        best_model = grid_search\n","\n","# Evaluate the best stacking ensemble on the test data\n","y_pred = best_model.predict(X_test_fe)\n","rmse = np.sqrt(mean_squared_error(y_test_fe, y_pred))\n","print(f\"Best stacking ensemble's RMSE on test data: {rmse}\")"]},{"cell_type":"markdown","metadata":{},"source":["定义了元模型候选列表 meta_models，其中包含了三个元模型：MLPRegressor、LinearRegression 和 XGBRegressor。\n","\n","为每个元模型定义了相应的超参数网格 meta_param_grids，用于后续的网格搜索。每个元模型的超参数网格都可以根据需求进行自定义。\n","\n","使用 KFold 创建了一个 3 折交叉验证对象 cv。\n","\n","然后，开始训练和调优堆叠集成模型。对于每个元模型，依次进行如下操作：\n","\n","创建一个 StackingRegressor 对象，并使用最佳基模型和当前元模型作为参数。\n","\n","使用 GridSearchCV 进行网格搜索，通过交叉验证选择出最佳的超参数配置。在网格搜索过程中，使用了之前创建的交叉验证对象 cv。\n","\n","输出当前元模型的最佳超参数和最佳均方根误差（负数形式）。\n","\n","如果当前元模型的最佳均方根误差比之前的模型更好，更新最佳模型和最佳分数。\n","\n","使用最佳模型在测试数据上进行预测，并计算预测结果与真实标签的均方根误差，并输出该结果。\n","\n","在代码中使用了 best_estimators 来作为基模型列表，这个列表是之前代码中定义的最佳基模型的集合。\n","\n","这段代码使用了StackingRegressor来构建一个堆叠集成模型，并通过网格搜索寻找最佳超参数配置。\n","\n","训练三个模型，并选出最好的。"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T12:11:30.569570Z","iopub.status.busy":"2023-10-10T12:11:30.569258Z","iopub.status.idle":"2023-10-10T12:11:30.703397Z","shell.execute_reply":"2023-10-10T12:11:30.702377Z","shell.execute_reply.started":"2023-10-10T12:11:30.569546Z"},"trusted":true},"outputs":[],"source":["y_stack = np.exp(best_model.predict(df_test_preprocessed))\n","\n","#xgboost submission\n","\n","df_stack_out = df_test[['Id']].copy()\n","df_stack_out['SalePrice'] = y_stack\n","\n","df_stack_out.to_csv('submission_stack_new_features_normalized.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["将id和堆叠比较中最好的模型的预测值组成一个两列的表格，输出为csv文件（选择的是fe和pca过的数据训练出来的那次模型）"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T12:12:00.991657Z","iopub.status.busy":"2023-10-10T12:12:00.991237Z","iopub.status.idle":"2023-10-10T12:12:01.008649Z","shell.execute_reply":"2023-10-10T12:12:01.007009Z","shell.execute_reply.started":"2023-10-10T12:12:00.991626Z"},"trusted":true},"outputs":[],"source":["df_stack_out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-10T12:12:17.222252Z","iopub.status.busy":"2023-10-10T12:12:17.221846Z","iopub.status.idle":"2023-10-10T12:12:17.230658Z","shell.execute_reply":"2023-10-10T12:12:17.229526Z","shell.execute_reply.started":"2023-10-10T12:12:17.222226Z"},"trusted":true},"outputs":[],"source":["df_stack_out.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
